{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public code for submitted paper \"DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\" for SIGKDD 2021. This code covers the experimental results in Chapter 5 in the submitted paper. Note that the following experiments are conducted on a randomly desensitized sampled dataset from original dataset (Region C) mentioned in the paper, all related id features are hashed for public use.\n",
    "\n",
    "This notebook is organized into 5 parts:\n",
    "1. Data Processing: generate the training data from the original log table (for log description, please refer to README.md file under ./data directory\n",
    "2. Baseline Models: corresponding to 5 baseline models compared in the submitted paper, including LR, GBDT, DNN, WDL and DIN model.\n",
    "3. Proposed Method: DMBGN: our proposed model, which includes experiment 2 variants of DMBGN (AvgPooling and Pretrained) with our final model DMBGN\n",
    "4. Summary: a summary of experiment results\n",
    "5. Reference\n",
    "\n",
    "The content of this notebook is as:\n",
    "- 1 Data Processing\n",
    "  - 1.1 Logs Processing\n",
    "  - 1.2 Label Encoding and Normalization\n",
    "- 2 Baseline Models\n",
    "  - 2.1 LR\n",
    "  - 2.2 GBDT\n",
    "  - 2.3 DNN\n",
    "  - 2.4 WDL\n",
    "  - 2.5 DIN\n",
    "- 3 Proposed Method: DMBGN\n",
    "  - 3.1 DMBGN-AvgPooling\n",
    "  - 3.2 DMBGN-Pretrained\n",
    "    - 3.2.1 UVG Graphs\n",
    "    - 3.2.2 GNN Networks\n",
    "      - 3.2.2.1 Get Pretrained Item Embedding\n",
    "      - 3.2.2.2 Train GNN\n",
    "      - 3.2.2.3 Generate Pretrained UVG Embedding\n",
    "      - 3.2.2.4 GMBDN Log Processing\n",
    "  - 3.3 DMBGN\n",
    "- 4 Summary\n",
    "- 5 Reference\n",
    "\n",
    "\n",
    "Note that you can run all codes directly for all the results. For DMBGN it might takes a longer time and we used 8 GPUs for accerlation purpose.\n",
    "\n",
    "\n",
    "Author: \\\n",
    "    Lin Li (boolean.ll@alibaba-inc.com) \\\n",
    "    Fengtong Xiao (fengtong.xiao@alibaba-inc.com) \\\n",
    "    Weinan Xu (stella.xu@lazada.com)\n",
    "\n",
    "References: \\\n",
    "    DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat,VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.setrecursionlimit(9000000) \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models.util import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device(idx=0):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "device_count = torch.cuda.device_count()\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62068, 19), (1118593, 14), (286735, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle file, note you might need to unzip the kdd_data.pkl.zip to recover the pkl file\n",
    "# To unzip, use the following linux commands:\n",
    "# $ cd ./data\n",
    "# $ unzip kdd_data.pkl.zip\n",
    "\n",
    "file_path = './data/kdd_data.pkl'\n",
    "with open(file_path, \"rb\") as f:\n",
    "    log_df = pickle.load(f)\n",
    "    session_df = pickle.load(f)\n",
    "    item_df = pickle.load(f)\n",
    "log_df.shape, session_df.shape, item_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logs Processing\n",
    "construct the historical UVG sequence following the chronological order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_purchase_level</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12130_38</td>\n",
       "      <td>1</td>\n",
       "      <td>12130</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>14363</td>\n",
       "      <td>28292</td>\n",
       "      <td>C3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>706.648652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.950388</td>\n",
       "      <td>11.584404</td>\n",
       "      <td>0.827519</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130_85</td>\n",
       "      <td>0</td>\n",
       "      <td>12130</td>\n",
       "      <td>85</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>49983</td>\n",
       "      <td>49983</td>\n",
       "      <td>C2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>822.218764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.165341</td>\n",
       "      <td>8.747008</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12156_64</td>\n",
       "      <td>0</td>\n",
       "      <td>12156</td>\n",
       "      <td>64</td>\n",
       "      <td>7799</td>\n",
       "      <td>700</td>\n",
       "      <td>21441</td>\n",
       "      <td>21441</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>349.797257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.703723</td>\n",
       "      <td>8.531640</td>\n",
       "      <td>0.928380</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12156_91</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>46418</td>\n",
       "      <td>52254</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>793.370613</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.778143</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12156_310</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>121387</td>\n",
       "      <td>131549</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>842.410759</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.589286</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62063</th>\n",
       "      <td>11873_319</td>\n",
       "      <td>0</td>\n",
       "      <td>11873</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>120575</td>\n",
       "      <td>120575</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62064</th>\n",
       "      <td>11873_305</td>\n",
       "      <td>1</td>\n",
       "      <td>11873</td>\n",
       "      <td>305</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>120576</td>\n",
       "      <td>131797</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62065</th>\n",
       "      <td>11879_159</td>\n",
       "      <td>0</td>\n",
       "      <td>11879</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>72071</td>\n",
       "      <td>72071</td>\n",
       "      <td>C0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>340.424720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.094769</td>\n",
       "      <td>28.368727</td>\n",
       "      <td>3.595659</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62066</th>\n",
       "      <td>11880_38</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>3867</td>\n",
       "      <td>4451</td>\n",
       "      <td>C3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>5085.468023</td>\n",
       "      <td>24.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62067</th>\n",
       "      <td>11880_454</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>454</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>125362</td>\n",
       "      <td>125362</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>7470.998268</td>\n",
       "      <td>34.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.852879</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62068 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0       12130_38      1   12130           38                888   \n",
       "1       12130_85      0   12130           85               4999   \n",
       "2       12156_64      0   12156           64               7799   \n",
       "3       12156_91      1   12156           91                799   \n",
       "4      12156_310      1   12156          310                349   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "62063  11873_319      0   11873          319               1999   \n",
       "62064  11873_305      1   11873          305               4999   \n",
       "62065  11879_159      0   11879          159                799   \n",
       "62066   11880_38      0   11880           38                888   \n",
       "62067  11880_454      0   11880          454                799   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    80                14363               28292   \n",
       "1                   500                49983               49983   \n",
       "2                   700                21441               21441   \n",
       "3                    80                46418               52254   \n",
       "4                    30               121387              131549   \n",
       "...                 ...                  ...                 ...   \n",
       "62063               200               120575              120575   \n",
       "62064               500               120576              131797   \n",
       "62065                70                72071               72071   \n",
       "62066                80                 3867                4451   \n",
       "62067                70               125362              125362   \n",
       "\n",
       "      campaign_name  user_age_level user_gender  user_purchase_level  \\\n",
       "0                C3             5.0           1                  8.0   \n",
       "1                C2             5.0           1                  8.0   \n",
       "2                C3             4.0           0                  9.0   \n",
       "3                C2             4.0           0                  9.0   \n",
       "4                C1             4.0           0                  9.0   \n",
       "...             ...             ...         ...                  ...   \n",
       "62063            C1             2.0           1                  9.0   \n",
       "62064            C1             2.0           1                  9.0   \n",
       "62065            C0             4.0           0                  8.0   \n",
       "62066            C3             2.0           1                  9.0   \n",
       "62067            C1             2.0           1                  9.0   \n",
       "\n",
       "       user_trd__orders_cnt_hist  user_trd__actual_gmv_usd_hist  \\\n",
       "0                           52.0                     706.648652   \n",
       "1                           69.0                     822.218764   \n",
       "2                           26.0                     349.797257   \n",
       "3                           61.0                     793.370613   \n",
       "4                           65.0                     842.410759   \n",
       "...                          ...                            ...   \n",
       "62063                       18.0                     884.002906   \n",
       "62064                       18.0                     884.002906   \n",
       "62065                       10.0                     340.424720   \n",
       "62066                      169.0                    5085.468023   \n",
       "62067                      214.0                    7470.998268   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              4.0   \n",
       "1                                              9.0   \n",
       "2                                              4.0   \n",
       "3                                              7.0   \n",
       "4                                              8.0   \n",
       "...                                            ...   \n",
       "62063                                         16.0   \n",
       "62064                                         16.0   \n",
       "62065                                          1.0   \n",
       "62066                                         24.0   \n",
       "62067                                         34.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                       79.950388                   11.584404   \n",
       "1                       60.165341                    8.747008   \n",
       "2                      118.703723                    8.531640   \n",
       "3                      215.294128                    7.778143   \n",
       "4                      215.294128                    7.589286   \n",
       "...                           ...                         ...   \n",
       "62063                  260.133633                   21.047688   \n",
       "62064                  260.133633                   21.047688   \n",
       "62065                   53.094769                   28.368727   \n",
       "62066                  501.537557                   14.009554   \n",
       "62067                  501.537557                   14.852879   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype  \n",
       "0                        0.827519  train  \n",
       "1                        0.601405   test  \n",
       "2                        0.928380   test  \n",
       "3                        0.517295   test  \n",
       "4                        0.517295  train  \n",
       "...                           ...    ...  \n",
       "62063                    0.000000  train  \n",
       "62064                    0.000000  train  \n",
       "62065                    3.595659   test  \n",
       "62066                    0.000000  train  \n",
       "62067                    0.094030   test  \n",
       "\n",
       "[62068 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"select *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY CAST(voucher_collect_time AS BIGINT) ASC) as rk from {logdf}\".format(logdf=\"log_df\")\n",
    "log_df = ps.sqldf(q1, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>rk</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>hist_rk</th>\n",
       "      <th>hist_voucher_collect_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>100489</td>\n",
       "      <td>132869</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.976711</td>\n",
       "      <td>8.408431</td>\n",
       "      <td>0.739039</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46827</td>\n",
       "      <td>48182</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.972645</td>\n",
       "      <td>3.039102</td>\n",
       "      <td>1.498169</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_82</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46227</td>\n",
       "      <td>46227</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>397.755770</td>\n",
       "      <td>17.843147</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000_386</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>96836</td>\n",
       "      <td>96836</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83457</th>\n",
       "      <td>6777_391</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>391</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>102</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83458</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_138</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>39379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83459</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_206</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>59004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83460</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_215</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>64992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83461</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83462 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1          1_425      0       1          425                 40   \n",
       "2          10_82      0      10           82                299   \n",
       "3         100_82      0     100           82                299   \n",
       "4       1000_386      0    1000          386                  0   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "83457   6777_391      0    6777          391                199   \n",
       "83458   6777_383      0    6777          383                500   \n",
       "83459   6777_383      0    6777          383                500   \n",
       "83460   6777_383      0    6777          383                500   \n",
       "83461   6777_383      0    6777          383                500   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                     4               100489              132869   \n",
       "2                    30                46827               48182   \n",
       "3                    30                46227               46227   \n",
       "4                    60                96836               96836   \n",
       "...                 ...                  ...                 ...   \n",
       "83457                30               128346              128346   \n",
       "83458                50               128346              128346   \n",
       "83459                50               128346              128346   \n",
       "83460                50               128346              128346   \n",
       "83461                50               128346              128346   \n",
       "\n",
       "      campaign_name  user_age_level  ...  \\\n",
       "0                C2             4.0  ...   \n",
       "1                C1             0.0  ...   \n",
       "2                C2             NaN  ...   \n",
       "3                C2             3.0  ...   \n",
       "4                C1             3.0  ...   \n",
       "...             ...             ...  ...   \n",
       "83457            C1             4.0  ...   \n",
       "83458            C1             4.0  ...   \n",
       "83459            C1             4.0  ...   \n",
       "83460            C1             4.0  ...   \n",
       "83461            C1             4.0  ...   \n",
       "\n",
       "      user_trd__orders_cnt_platform_discount_hist  user_trd__max_gmv_usd_hist  \\\n",
       "0                                             0.0                    6.376755   \n",
       "1                                             1.0                   27.976711   \n",
       "2                                             0.0                    4.972645   \n",
       "3                                            34.0                  397.755770   \n",
       "4                                             0.0                    0.000000   \n",
       "...                                           ...                         ...   \n",
       "83457                                        50.0                   93.471440   \n",
       "83458                                        50.0                   93.471440   \n",
       "83459                                        50.0                   93.471440   \n",
       "83460                                        50.0                   93.471440   \n",
       "83461                                        50.0                   93.471440   \n",
       "\n",
       "       user_trd__avg_gmv_usd_hist  user_trd__min_gmv_usd_hist  dtype   rk  \\\n",
       "0                        3.917888                    2.518198  train    1   \n",
       "1                        8.408431                    0.739039  train    1   \n",
       "2                        3.039102                    1.498169  train    1   \n",
       "3                       17.843147                    0.003525  train    1   \n",
       "4                        0.000000                    0.000000  train    1   \n",
       "...                           ...                         ...    ...  ...   \n",
       "83457                    7.419820                    0.000000  train  102   \n",
       "83458                    7.419820                    0.000000  train  103   \n",
       "83459                    7.419820                    0.000000  train  103   \n",
       "83460                    7.419820                    0.000000  train  103   \n",
       "83461                    7.419820                    0.000000  train  103   \n",
       "\n",
       "       hist_session_id  hist_promotion_id hist_rk  hist_voucher_collect_time  \n",
       "0                                                                       None  \n",
       "1                                                                       None  \n",
       "2                                                                       None  \n",
       "3                                                                       None  \n",
       "4                                                                       None  \n",
       "...                ...                ...     ...                        ...  \n",
       "83457         6777_248                248      39                      74788  \n",
       "83458         6777_138                138       2                      39379  \n",
       "83459         6777_206                206      17                      59004  \n",
       "83460         6777_215                215      27                      64992  \n",
       "83461         6777_248                248      39                      74788  \n",
       "\n",
       "[83462 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \" SELECT L.* \\\n",
    "            , coalesce(R.session_id, '') AS hist_session_id \\\n",
    "            , coalesce(R.promotion_id, '') AS hist_promotion_id \\\n",
    "            , coalesce(R.rk, '') AS hist_rk \\\n",
    "            , R.voucher_collect_time AS hist_voucher_collect_time \\\n",
    "        FROM {df} L \\\n",
    "        LEFT JOIN {df} R \\\n",
    "        ON L.user_id = R.user_id \\\n",
    "        AND L.session_id != R.session_id \\\n",
    "        AND L.campaign_name != R.campaign_name \\\n",
    "        AND R.label = 1 \\\n",
    "        AND L.rk > R.rk \\\n",
    "        ORDER BY L.rk ASC, R.rk ASC\".format(df='log_df')\n",
    "log_df_tmp = ps.sqldf(sql, locals())\n",
    "log_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_voucher_log = log_df_tmp.groupby([ 'session_id', 'label', 'user_id', 'promotion_id', 'voucher_min_spend', \n",
    "                       'voucher_discount', 'voucher_collect_time', 'voucher_redeem_time',\n",
    "                       'user_age_level', 'user_gender', 'user_purchase_level',\n",
    "                       'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist',\n",
    "                       'user_trd__orders_cnt_platform_discount_hist',\n",
    "                       'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist',\n",
    "                       'user_trd__min_gmv_usd_hist', 'dtype']) \\\n",
    "                .agg({'hist_session_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_promotion_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_rk': lambda x: list(x),\n",
    "                      'hist_voucher_collect_time': \"count\"}).reset_index()\n",
    "\n",
    "user_voucher_log['keys_length'] = user_voucher_log['hist_voucher_collect_time']\n",
    "user_voucher_log = user_voucher_log.drop(columns=['hist_rk', 'hist_voucher_collect_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>keys_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.507327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>13253</td>\n",
       "      <td>13254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.105824</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.643151</td>\n",
       "      <td>12.116990</td>\n",
       "      <td>3.581674</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_159</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>80001</td>\n",
       "      <td>89306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>373.530611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>6.225510</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001_319</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>115663</td>\n",
       "      <td>115663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>381.810513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>5.614860</td>\n",
       "      <td>0.487420</td>\n",
       "      <td>train</td>\n",
       "      <td>10001_159</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>12867</td>\n",
       "      <td>19625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>133.172685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.419591</td>\n",
       "      <td>11.097724</td>\n",
       "      <td>1.811817</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58046</th>\n",
       "      <td>99_82</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46577</td>\n",
       "      <td>46577</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2462.818244</td>\n",
       "      <td>50.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>18.944756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58047</th>\n",
       "      <td>99_83</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>83</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>35523</td>\n",
       "      <td>53242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58048</th>\n",
       "      <td>99_91</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>35523</td>\n",
       "      <td>46578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58049</th>\n",
       "      <td>9_61</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>2999</td>\n",
       "      <td>300</td>\n",
       "      <td>24981</td>\n",
       "      <td>28017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58050</th>\n",
       "      <td>9_69</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58051 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1       10000_38      0   10000           38                888   \n",
       "2      10001_159      1   10001          159                799   \n",
       "3      10001_319      0   10001          319               1999   \n",
       "4       10001_38      0   10001           38                888   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "58046      99_82      0      99           82                299   \n",
       "58047      99_83      1      99           83               1999   \n",
       "58048      99_91      0      99           91                799   \n",
       "58049       9_61      1       9           61               2999   \n",
       "58050       9_69      0       9           69                888   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                    80                13253               13254   \n",
       "2                    70                80001               89306   \n",
       "3                   200               115663              115663   \n",
       "4                    80                12867               19625   \n",
       "...                 ...                  ...                 ...   \n",
       "58046                30                46577               46577   \n",
       "58047               200                35523               53242   \n",
       "58048                80                35523               46578   \n",
       "58049               300                24981               28017   \n",
       "58050                80                24983               24983   \n",
       "\n",
       "       user_age_level user_gender  ...  user_trd__orders_cnt_hist  \\\n",
       "0                 4.0           0  ...                        4.0   \n",
       "1                 3.0           0  ...                        6.0   \n",
       "2                 0.0           0  ...                       39.0   \n",
       "3                 0.0           0  ...                       42.0   \n",
       "4                 0.0           0  ...                       11.0   \n",
       "...               ...         ...  ...                        ...   \n",
       "58046             3.0           0  ...                       44.0   \n",
       "58047             3.0           0  ...                       43.0   \n",
       "58048             3.0           0  ...                       43.0   \n",
       "58049             3.0           1  ...                       22.0   \n",
       "58050             3.0           1  ...                       22.0   \n",
       "\n",
       "       user_trd__actual_gmv_usd_hist  \\\n",
       "0                          23.507327   \n",
       "1                         218.105824   \n",
       "2                         373.530611   \n",
       "3                         381.810513   \n",
       "4                         133.172685   \n",
       "...                              ...   \n",
       "58046                    2462.818244   \n",
       "58047                    2397.249462   \n",
       "58048                    2397.249462   \n",
       "58049                     715.893947   \n",
       "58050                     715.893947   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              0.0   \n",
       "1                                              9.0   \n",
       "2                                              3.0   \n",
       "3                                              3.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "58046                                         50.0   \n",
       "58047                                         46.0   \n",
       "58048                                         46.0   \n",
       "58049                                         23.0   \n",
       "58050                                         23.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                        6.376755                    3.917888   \n",
       "1                       42.643151                   12.116990   \n",
       "2                       32.090705                    6.225510   \n",
       "3                       32.090705                    5.614860   \n",
       "4                       26.419591                   11.097724   \n",
       "...                           ...                         ...   \n",
       "58046                  329.698604                   18.944756   \n",
       "58047                  329.698604                   19.025789   \n",
       "58048                  329.698604                   19.025789   \n",
       "58049                  150.129713                    9.419657   \n",
       "58050                  150.129713                    9.419657   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype hist_session_id hist_promotion_id  \\\n",
       "0                        2.518198  train                                     \n",
       "1                        3.581674  train                                     \n",
       "2                        0.561611  train                                     \n",
       "3                        0.487420  train       10001_159               159   \n",
       "4                        1.811817  train                                     \n",
       "...                           ...    ...             ...               ...   \n",
       "58046                    0.000000  train                                     \n",
       "58047                    0.000000   test                                     \n",
       "58048                    0.000000  train                                     \n",
       "58049                    1.116494  train                                     \n",
       "58050                    1.116494  train                                     \n",
       "\n",
       "      keys_length  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "...           ...  \n",
       "58046           0  \n",
       "58047           0  \n",
       "58048           0  \n",
       "58049           0  \n",
       "58050           0  \n",
       "\n",
       "[58051 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_voucher_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys_length</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keys_length  session_id\n",
       "0             0       39908\n",
       "1             1        8720\n",
       "2             2        4236\n",
       "3             3        2326\n",
       "4             4        1325\n",
       "5             5         721\n",
       "6             6         267\n",
       "7             7         218\n",
       "8             8         115\n",
       "9             9          72\n",
       "10           10          44\n",
       "11           11          45\n",
       "12           12          10\n",
       "13           13          13\n",
       "14           14          12\n",
       "15           18          19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a statistics of historical UVG sequence distribution\n",
    "user_voucher_log.groupby(['keys_length']).agg({'session_id': \"count\"}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding and Normalization\n",
    "Label encoding for sparse features and normlaization for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_session_id','keys_length']\n",
    "\n",
    "ignore_features=['dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "ignore_features_key_words = ['out', 'emb']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    flag = True \n",
    "    for key in ignore_features_key_words:\n",
    "        if key in feat:\n",
    "            flag = False\n",
    "            break\n",
    "    if feat not in ignore_features and flag is True:\n",
    "        if feat not in hist_list_features:\n",
    "            train_features.append(feat)\n",
    "        if feat not in sparse_feature and feat not in hist_list_features:\n",
    "            dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 18:17:13,783 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 18:17:14,019 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2021-06-01 18:17:14,104 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2021-06-01 18:17:14,177 [WARNING]: LabelEncoder encoding user_age_level len 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 18:17:14,251 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    \n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "        \n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_ctr_df = df \n",
    "\n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "sparse_feature_columns = [SparseFeat(feat, len(label_encoder[feat].classes_), embedding_dim = embedding_dim) for feat in sparse_feature]\n",
    "dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_feature]\n",
    "\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "LR: Logistic Regression [1] is a shallow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input_data(feature_names, raw_features, target):\n",
    "    model_input = {}\n",
    "    for name in feature_names:\n",
    "        if name in sparse_feature:\n",
    "            model_input[name] = raw_features[name]\n",
    "        else:\n",
    "            model_input[name] = raw_features[name].fillna(0).astype(np.float32)\n",
    "    return raw_features[target], model_input\n",
    "\n",
    "feature_names = get_feature_names(dense_feature_columns + sparse_feature_columns)\n",
    "train_label, train_model_input = gen_model_input_data(feature_names, dctr_train, target)\n",
    "test_label1, test_model_input1 = gen_model_input_data(feature_names, dctr_v1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 117.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.07it/s]\n",
      "14it [00:00, 131.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1s - loss:  0.5970 - auc:  0.5655 - logloss:  0.5947 - val_auc:  0.6099 - val_logloss:  0.5215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.92it/s]\n",
      "14it [00:00, 131.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "1s - loss:  0.4861 - auc:  0.7432 - logloss:  0.4839 - val_auc:  0.6739 - val_logloss:  0.4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.99it/s]\n",
      "14it [00:00, 131.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1s - loss:  0.4459 - auc:  0.7680 - logloss:  0.4438 - val_auc:  0.7053 - val_logloss:  0.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.98it/s]\n",
      "14it [00:00, 131.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "1s - loss:  0.4297 - auc:  0.7746 - logloss:  0.4276 - val_auc:  0.7201 - val_logloss:  0.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 122.51it/s]\n",
      "14it [00:00, 130.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1s - loss:  0.4211 - auc:  0.7735 - logloss:  0.4194 - val_auc:  0.7267 - val_logloss:  0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.23it/s]\n",
      "11it [00:00, 104.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1s - loss:  0.4152 - auc:  0.7716 - logloss:  0.4133 - val_auc:  0.7295 - val_logloss:  0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 129.37it/s]\n",
      "11it [00:00, 104.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "1s - loss:  0.4106 - auc:  0.7699 - logloss:  0.4084 - val_auc:  0.7308 - val_logloss:  0.4108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 129.62it/s]\n",
      "11it [00:00, 105.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "1s - loss:  0.4068 - auc:  0.7679 - logloss:  0.4047 - val_auc:  0.7319 - val_logloss:  0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 129.68it/s]\n",
      "11it [00:00, 105.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "1s - loss:  0.4037 - auc:  0.7663 - logloss:  0.4016 - val_auc:  0.7323 - val_logloss:  0.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 129.46it/s]\n",
      "11it [00:00, 101.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1s - loss:  0.4011 - auc:  0.7656 - logloss:  0.3995 - val_auc:  0.7328 - val_logloss:  0.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 130.56it/s]\n",
      "14it [00:00, 131.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1s - loss:  0.3989 - auc:  0.7639 - logloss:  0.3968 - val_auc:  0.7333 - val_logloss:  0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.44it/s]\n",
      "14it [00:00, 131.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "1s - loss:  0.3971 - auc:  0.7635 - logloss:  0.3953 - val_auc:  0.7338 - val_logloss:  0.3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.61it/s]\n",
      "14it [00:00, 132.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1s - loss:  0.3956 - auc:  0.7627 - logloss:  0.3935 - val_auc:  0.7342 - val_logloss:  0.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.29it/s]\n",
      "14it [00:00, 132.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1s - loss:  0.3943 - auc:  0.7622 - logloss:  0.3926 - val_auc:  0.7345 - val_logloss:  0.3974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.17it/s]\n",
      "14it [00:00, 132.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1s - loss:  0.3932 - auc:  0.7625 - logloss:  0.3913 - val_auc:  0.7348 - val_logloss:  0.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 122.38it/s]\n",
      "14it [00:00, 132.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "1s - loss:  0.3922 - auc:  0.7627 - logloss:  0.3902 - val_auc:  0.7351 - val_logloss:  0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.23it/s]\n",
      "14it [00:00, 132.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "1s - loss:  0.3914 - auc:  0.7622 - logloss:  0.3895 - val_auc:  0.7354 - val_logloss:  0.3950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.26it/s]\n",
      "14it [00:00, 132.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1s - loss:  0.3907 - auc:  0.7616 - logloss:  0.3890 - val_auc:  0.7356 - val_logloss:  0.3944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.48it/s]\n",
      "14it [00:00, 132.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "1s - loss:  0.3901 - auc:  0.7615 - logloss:  0.3881 - val_auc:  0.7358 - val_logloss:  0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.07it/s]\n",
      "14it [00:00, 132.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1s - loss:  0.3896 - auc:  0.7615 - logloss:  0.3877 - val_auc:  0.7360 - val_logloss:  0.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 123.49it/s]\n",
      "14it [00:00, 132.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "1s - loss:  0.3891 - auc:  0.7606 - logloss:  0.3872 - val_auc:  0.7361 - val_logloss:  0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.09it/s]\n",
      "14it [00:00, 132.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "1s - loss:  0.3887 - auc:  0.7612 - logloss:  0.3867 - val_auc:  0.7363 - val_logloss:  0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.89it/s]\n",
      "14it [00:00, 132.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "1s - loss:  0.3884 - auc:  0.7599 - logloss:  0.3864 - val_auc:  0.7364 - val_logloss:  0.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.20it/s]\n",
      "14it [00:00, 132.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "1s - loss:  0.3881 - auc:  0.7604 - logloss:  0.3862 - val_auc:  0.7365 - val_logloss:  0.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.18it/s]\n",
      "14it [00:00, 132.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1s - loss:  0.3878 - auc:  0.7607 - logloss:  0.3856 - val_auc:  0.7367 - val_logloss:  0.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.34it/s]\n",
      "14it [00:00, 131.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1s - loss:  0.3875 - auc:  0.7608 - logloss:  0.3858 - val_auc:  0.7368 - val_logloss:  0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.90it/s]\n",
      "13it [00:00, 129.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "1s - loss:  0.3873 - auc:  0.7606 - logloss:  0.3852 - val_auc:  0.7368 - val_logloss:  0.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.97it/s]\n",
      "14it [00:00, 130.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1s - loss:  0.3871 - auc:  0.7607 - logloss:  0.3854 - val_auc:  0.7369 - val_logloss:  0.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.02it/s]\n",
      "14it [00:00, 130.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1s - loss:  0.3869 - auc:  0.7603 - logloss:  0.3848 - val_auc:  0.7370 - val_logloss:  0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.71it/s]\n",
      "14it [00:00, 130.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1s - loss:  0.3868 - auc:  0.7601 - logloss:  0.3849 - val_auc:  0.7370 - val_logloss:  0.3909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.75it/s]\n",
      "14it [00:00, 130.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "1s - loss:  0.3866 - auc:  0.7607 - logloss:  0.3847 - val_auc:  0.7371 - val_logloss:  0.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 122.69it/s]\n",
      "13it [00:00, 129.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "1s - loss:  0.3865 - auc:  0.7598 - logloss:  0.3846 - val_auc:  0.7371 - val_logloss:  0.3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.75it/s]\n",
      "14it [00:00, 130.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1s - loss:  0.3864 - auc:  0.7601 - logloss:  0.3844 - val_auc:  0.7373 - val_logloss:  0.3906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.63it/s]\n",
      "13it [00:00, 129.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1s - loss:  0.3863 - auc:  0.7607 - logloss:  0.3844 - val_auc:  0.7373 - val_logloss:  0.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.00it/s]\n",
      "14it [00:00, 132.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1s - loss:  0.3861 - auc:  0.7609 - logloss:  0.3843 - val_auc:  0.7373 - val_logloss:  0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 135.14it/s]\n",
      "14it [00:00, 132.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "1s - loss:  0.3861 - auc:  0.7603 - logloss:  0.3841 - val_auc:  0.7373 - val_logloss:  0.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 123.16it/s]\n",
      "13it [00:00, 129.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1s - loss:  0.3860 - auc:  0.7610 - logloss:  0.3844 - val_auc:  0.7374 - val_logloss:  0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 131.71it/s]\n",
      "14it [00:00, 130.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1s - loss:  0.3859 - auc:  0.7601 - logloss:  0.3842 - val_auc:  0.7374 - val_logloss:  0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.93it/s]\n",
      "14it [00:00, 131.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1s - loss:  0.3859 - auc:  0.7609 - logloss:  0.3839 - val_auc:  0.7375 - val_logloss:  0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.28it/s]\n",
      "14it [00:00, 131.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1s - loss:  0.3858 - auc:  0.7607 - logloss:  0.3839 - val_auc:  0.7375 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.24it/s]\n",
      "14it [00:00, 131.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1s - loss:  0.3857 - auc:  0.7597 - logloss:  0.3836 - val_auc:  0.7375 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.29it/s]\n",
      "13it [00:00, 129.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1s - loss:  0.3857 - auc:  0.7601 - logloss:  0.3836 - val_auc:  0.7376 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.79it/s]\n",
      "14it [00:00, 131.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "1s - loss:  0.3856 - auc:  0.7604 - logloss:  0.3836 - val_auc:  0.7376 - val_logloss:  0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.07it/s]\n",
      "14it [00:00, 131.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "1s - loss:  0.3856 - auc:  0.7598 - logloss:  0.3837 - val_auc:  0.7375 - val_logloss:  0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.18it/s]\n",
      "14it [00:00, 131.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1s - loss:  0.3856 - auc:  0.7602 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.18it/s]\n",
      "14it [00:00, 130.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "1s - loss:  0.3855 - auc:  0.7602 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.90it/s]\n",
      "14it [00:00, 131.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "1s - loss:  0.3855 - auc:  0.7602 - logloss:  0.3834 - val_auc:  0.7377 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 122.43it/s]\n",
      "14it [00:00, 131.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "1s - loss:  0.3854 - auc:  0.7605 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 133.96it/s]\n",
      "14it [00:00, 131.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1s - loss:  0.3854 - auc:  0.7600 - logloss:  0.3832 - val_auc:  0.7376 - val_logloss:  0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 134.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1s - loss:  0.3854 - auc:  0.7609 - logloss:  0.3834 - val_auc:  0.7377 - val_logloss:  0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR'\n",
    "epoch = 50\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=dnn_feature_columns,\n",
    "            dnn_feature_columns=[], \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT\n",
    "GBDT: Gradient Boosting Decision Tree [2] is used to assess the performance of non deep-learning algorithms. Only dense features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:28:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\teval-auc:0.74426\teval-logloss:0.66234\ttrain-auc:0.75173\ttrain-logloss:0.66225\n",
      "[1]\teval-auc:0.74628\teval-logloss:0.63497\ttrain-auc:0.75559\ttrain-logloss:0.63484\n",
      "[2]\teval-auc:0.74539\teval-logloss:0.61074\ttrain-auc:0.75743\ttrain-logloss:0.61042\n",
      "[3]\teval-auc:0.74809\teval-logloss:0.58899\ttrain-auc:0.76167\ttrain-logloss:0.58850\n",
      "[4]\teval-auc:0.74831\teval-logloss:0.56951\ttrain-auc:0.76250\ttrain-logloss:0.56880\n",
      "[5]\teval-auc:0.74857\teval-logloss:0.55195\ttrain-auc:0.76321\ttrain-logloss:0.55111\n",
      "[6]\teval-auc:0.74915\teval-logloss:0.53605\ttrain-auc:0.76352\ttrain-logloss:0.53516\n",
      "[7]\teval-auc:0.74995\teval-logloss:0.52171\ttrain-auc:0.76406\ttrain-logloss:0.52070\n",
      "[8]\teval-auc:0.75152\teval-logloss:0.50867\ttrain-auc:0.76670\ttrain-logloss:0.50752\n",
      "[9]\teval-auc:0.75175\teval-logloss:0.49694\ttrain-auc:0.76707\ttrain-logloss:0.49556\n",
      "[10]\teval-auc:0.75225\teval-logloss:0.48625\ttrain-auc:0.76788\ttrain-logloss:0.48474\n",
      "[11]\teval-auc:0.75309\teval-logloss:0.47645\ttrain-auc:0.76881\ttrain-logloss:0.47479\n",
      "[12]\teval-auc:0.75355\teval-logloss:0.46759\ttrain-auc:0.76983\ttrain-logloss:0.46575\n",
      "[13]\teval-auc:0.75421\teval-logloss:0.45951\ttrain-auc:0.77044\ttrain-logloss:0.45752\n",
      "[14]\teval-auc:0.75502\teval-logloss:0.45212\ttrain-auc:0.77164\ttrain-logloss:0.44999\n",
      "[15]\teval-auc:0.75644\teval-logloss:0.44536\ttrain-auc:0.77403\ttrain-logloss:0.44303\n",
      "[16]\teval-auc:0.75662\teval-logloss:0.43921\ttrain-auc:0.77462\ttrain-logloss:0.43667\n",
      "[17]\teval-auc:0.75641\teval-logloss:0.43364\ttrain-auc:0.77521\ttrain-logloss:0.43089\n",
      "[18]\teval-auc:0.75678\teval-logloss:0.42851\ttrain-auc:0.77555\ttrain-logloss:0.42560\n",
      "[19]\teval-auc:0.75750\teval-logloss:0.42374\ttrain-auc:0.77684\ttrain-logloss:0.42059\n",
      "[20]\teval-auc:0.75767\teval-logloss:0.41939\ttrain-auc:0.77741\ttrain-logloss:0.41596\n",
      "[21]\teval-auc:0.75785\teval-logloss:0.41545\ttrain-auc:0.77776\ttrain-logloss:0.41180\n",
      "[22]\teval-auc:0.75787\teval-logloss:0.41176\ttrain-auc:0.77826\ttrain-logloss:0.40788\n",
      "[23]\teval-auc:0.75887\teval-logloss:0.40837\ttrain-auc:0.77969\ttrain-logloss:0.40425\n",
      "[24]\teval-auc:0.75993\teval-logloss:0.40513\ttrain-auc:0.78142\ttrain-logloss:0.40073\n",
      "[25]\teval-auc:0.76011\teval-logloss:0.40227\ttrain-auc:0.78184\ttrain-logloss:0.39764\n",
      "[26]\teval-auc:0.76183\teval-logloss:0.39934\ttrain-auc:0.78374\ttrain-logloss:0.39453\n",
      "[27]\teval-auc:0.76191\teval-logloss:0.39693\ttrain-auc:0.78409\ttrain-logloss:0.39187\n",
      "[28]\teval-auc:0.76292\teval-logloss:0.39448\ttrain-auc:0.78579\ttrain-logloss:0.38916\n",
      "[29]\teval-auc:0.76343\teval-logloss:0.39242\ttrain-auc:0.78652\ttrain-logloss:0.38687\n",
      "[30]\teval-auc:0.76346\teval-logloss:0.39054\ttrain-auc:0.78683\ttrain-logloss:0.38477\n",
      "[31]\teval-auc:0.76377\teval-logloss:0.38880\ttrain-auc:0.78757\ttrain-logloss:0.38277\n",
      "[32]\teval-auc:0.76405\teval-logloss:0.38716\ttrain-auc:0.78777\ttrain-logloss:0.38093\n",
      "[33]\teval-auc:0.76430\teval-logloss:0.38567\ttrain-auc:0.78831\ttrain-logloss:0.37923\n",
      "[34]\teval-auc:0.76505\teval-logloss:0.38410\ttrain-auc:0.78952\ttrain-logloss:0.37740\n",
      "[35]\teval-auc:0.76545\teval-logloss:0.38287\ttrain-auc:0.79021\ttrain-logloss:0.37595\n",
      "[36]\teval-auc:0.76622\teval-logloss:0.38148\ttrain-auc:0.79155\ttrain-logloss:0.37431\n",
      "[37]\teval-auc:0.76628\teval-logloss:0.38045\ttrain-auc:0.79214\ttrain-logloss:0.37298\n",
      "[38]\teval-auc:0.76661\teval-logloss:0.37938\ttrain-auc:0.79245\ttrain-logloss:0.37174\n",
      "[39]\teval-auc:0.76772\teval-logloss:0.37825\ttrain-auc:0.79411\ttrain-logloss:0.37027\n",
      "[40]\teval-auc:0.76803\teval-logloss:0.37738\ttrain-auc:0.79428\ttrain-logloss:0.36922\n",
      "[41]\teval-auc:0.76837\teval-logloss:0.37658\ttrain-auc:0.79505\ttrain-logloss:0.36812\n",
      "[42]\teval-auc:0.76888\teval-logloss:0.37572\ttrain-auc:0.79580\ttrain-logloss:0.36698\n",
      "[43]\teval-auc:0.76896\teval-logloss:0.37509\ttrain-auc:0.79647\ttrain-logloss:0.36601\n",
      "[44]\teval-auc:0.76906\teval-logloss:0.37447\ttrain-auc:0.79715\ttrain-logloss:0.36508\n",
      "[45]\teval-auc:0.76935\teval-logloss:0.37385\ttrain-auc:0.79800\ttrain-logloss:0.36412\n",
      "[46]\teval-auc:0.76971\teval-logloss:0.37323\ttrain-auc:0.79879\ttrain-logloss:0.36323\n",
      "[47]\teval-auc:0.77003\teval-logloss:0.37264\ttrain-auc:0.79968\ttrain-logloss:0.36234\n",
      "[48]\teval-auc:0.77020\teval-logloss:0.37216\ttrain-auc:0.80019\ttrain-logloss:0.36159\n",
      "[49]\teval-auc:0.77072\teval-logloss:0.37160\ttrain-auc:0.80125\ttrain-logloss:0.36070\n",
      "[50]\teval-auc:0.77097\teval-logloss:0.37112\ttrain-auc:0.80188\ttrain-logloss:0.36001\n",
      "[51]\teval-auc:0.77107\teval-logloss:0.37070\ttrain-auc:0.80229\ttrain-logloss:0.35932\n",
      "[52]\teval-auc:0.77138\teval-logloss:0.37028\ttrain-auc:0.80319\ttrain-logloss:0.35855\n",
      "[53]\teval-auc:0.77144\teval-logloss:0.36993\ttrain-auc:0.80353\ttrain-logloss:0.35798\n",
      "[54]\teval-auc:0.77178\teval-logloss:0.36954\ttrain-auc:0.80439\ttrain-logloss:0.35729\n",
      "[55]\teval-auc:0.77178\teval-logloss:0.36930\ttrain-auc:0.80521\ttrain-logloss:0.35665\n",
      "[56]\teval-auc:0.77187\teval-logloss:0.36904\ttrain-auc:0.80581\ttrain-logloss:0.35608\n",
      "[57]\teval-auc:0.77202\teval-logloss:0.36877\ttrain-auc:0.80689\ttrain-logloss:0.35540\n",
      "[58]\teval-auc:0.77216\teval-logloss:0.36853\ttrain-auc:0.80736\ttrain-logloss:0.35483\n",
      "[59]\teval-auc:0.77214\teval-logloss:0.36835\ttrain-auc:0.80795\ttrain-logloss:0.35433\n",
      "[60]\teval-auc:0.77260\teval-logloss:0.36806\ttrain-auc:0.80875\ttrain-logloss:0.35378\n",
      "[61]\teval-auc:0.77280\teval-logloss:0.36786\ttrain-auc:0.80912\ttrain-logloss:0.35335\n",
      "[62]\teval-auc:0.77297\teval-logloss:0.36762\ttrain-auc:0.80992\ttrain-logloss:0.35282\n",
      "[63]\teval-auc:0.77302\teval-logloss:0.36744\ttrain-auc:0.81052\ttrain-logloss:0.35235\n",
      "[64]\teval-auc:0.77307\teval-logloss:0.36731\ttrain-auc:0.81174\ttrain-logloss:0.35179\n",
      "[65]\teval-auc:0.77307\teval-logloss:0.36719\ttrain-auc:0.81231\ttrain-logloss:0.35133\n",
      "[66]\teval-auc:0.77315\teval-logloss:0.36706\ttrain-auc:0.81261\ttrain-logloss:0.35095\n",
      "[67]\teval-auc:0.77349\teval-logloss:0.36683\ttrain-auc:0.81419\ttrain-logloss:0.35027\n",
      "[68]\teval-auc:0.77338\teval-logloss:0.36674\ttrain-auc:0.81524\ttrain-logloss:0.34968\n",
      "[69]\teval-auc:0.77355\teval-logloss:0.36658\ttrain-auc:0.81586\ttrain-logloss:0.34922\n",
      "[70]\teval-auc:0.77355\teval-logloss:0.36652\ttrain-auc:0.81619\ttrain-logloss:0.34889\n",
      "[71]\teval-auc:0.77383\teval-logloss:0.36634\ttrain-auc:0.81701\ttrain-logloss:0.34839\n",
      "[72]\teval-auc:0.77409\teval-logloss:0.36613\ttrain-auc:0.81787\ttrain-logloss:0.34787\n",
      "[73]\teval-auc:0.77436\teval-logloss:0.36599\ttrain-auc:0.81878\ttrain-logloss:0.34735\n",
      "[74]\teval-auc:0.77428\teval-logloss:0.36592\ttrain-auc:0.81960\ttrain-logloss:0.34686\n",
      "[75]\teval-auc:0.77443\teval-logloss:0.36580\ttrain-auc:0.82050\ttrain-logloss:0.34632\n",
      "[76]\teval-auc:0.77456\teval-logloss:0.36566\ttrain-auc:0.82090\ttrain-logloss:0.34594\n",
      "[77]\teval-auc:0.77480\teval-logloss:0.36553\ttrain-auc:0.82142\ttrain-logloss:0.34559\n",
      "[78]\teval-auc:0.77486\teval-logloss:0.36548\ttrain-auc:0.82180\ttrain-logloss:0.34527\n",
      "[79]\teval-auc:0.77484\teval-logloss:0.36540\ttrain-auc:0.82228\ttrain-logloss:0.34489\n",
      "[80]\teval-auc:0.77501\teval-logloss:0.36525\ttrain-auc:0.82292\ttrain-logloss:0.34445\n",
      "[81]\teval-auc:0.77515\teval-logloss:0.36518\ttrain-auc:0.82339\ttrain-logloss:0.34415\n",
      "[82]\teval-auc:0.77533\teval-logloss:0.36508\ttrain-auc:0.82409\ttrain-logloss:0.34381\n",
      "[83]\teval-auc:0.77534\teval-logloss:0.36500\ttrain-auc:0.82465\ttrain-logloss:0.34340\n",
      "[84]\teval-auc:0.77549\teval-logloss:0.36490\ttrain-auc:0.82509\ttrain-logloss:0.34309\n",
      "[85]\teval-auc:0.77540\teval-logloss:0.36490\ttrain-auc:0.82568\ttrain-logloss:0.34274\n",
      "[86]\teval-auc:0.77538\teval-logloss:0.36485\ttrain-auc:0.82571\ttrain-logloss:0.34260\n",
      "[87]\teval-auc:0.77535\teval-logloss:0.36486\ttrain-auc:0.82620\ttrain-logloss:0.34233\n",
      "[88]\teval-auc:0.77532\teval-logloss:0.36484\ttrain-auc:0.82652\ttrain-logloss:0.34203\n",
      "[89]\teval-auc:0.77534\teval-logloss:0.36478\ttrain-auc:0.82702\ttrain-logloss:0.34178\n",
      "[90]\teval-auc:0.77543\teval-logloss:0.36471\ttrain-auc:0.82736\ttrain-logloss:0.34150\n",
      "[91]\teval-auc:0.77545\teval-logloss:0.36466\ttrain-auc:0.82782\ttrain-logloss:0.34124\n",
      "[92]\teval-auc:0.77571\teval-logloss:0.36450\ttrain-auc:0.82843\ttrain-logloss:0.34080\n",
      "[93]\teval-auc:0.77577\teval-logloss:0.36448\ttrain-auc:0.82886\ttrain-logloss:0.34059\n",
      "[94]\teval-auc:0.77581\teval-logloss:0.36446\ttrain-auc:0.82913\ttrain-logloss:0.34035\n",
      "[95]\teval-auc:0.77584\teval-logloss:0.36447\ttrain-auc:0.82944\ttrain-logloss:0.34017\n",
      "[96]\teval-auc:0.77573\teval-logloss:0.36448\ttrain-auc:0.82984\ttrain-logloss:0.33989\n",
      "[97]\teval-auc:0.77585\teval-logloss:0.36442\ttrain-auc:0.83057\ttrain-logloss:0.33958\n",
      "[98]\teval-auc:0.77578\teval-logloss:0.36444\ttrain-auc:0.83085\ttrain-logloss:0.33938\n",
      "[99]\teval-auc:0.77582\teval-logloss:0.36445\ttrain-auc:0.83106\ttrain-logloss:0.33927\n",
      "[100]\teval-auc:0.77615\teval-logloss:0.36430\ttrain-auc:0.83159\ttrain-logloss:0.33888\n",
      "[101]\teval-auc:0.77621\teval-logloss:0.36426\ttrain-auc:0.83198\ttrain-logloss:0.33866\n",
      "[102]\teval-auc:0.77626\teval-logloss:0.36422\ttrain-auc:0.83243\ttrain-logloss:0.33840\n",
      "[103]\teval-auc:0.77624\teval-logloss:0.36424\ttrain-auc:0.83250\ttrain-logloss:0.33834\n",
      "[104]\teval-auc:0.77633\teval-logloss:0.36415\ttrain-auc:0.83272\ttrain-logloss:0.33811\n",
      "[105]\teval-auc:0.77618\teval-logloss:0.36415\ttrain-auc:0.83314\ttrain-logloss:0.33781\n",
      "[106]\teval-auc:0.77615\teval-logloss:0.36417\ttrain-auc:0.83333\ttrain-logloss:0.33771\n",
      "[107]\teval-auc:0.77643\teval-logloss:0.36406\ttrain-auc:0.83384\ttrain-logloss:0.33743\n",
      "[108]\teval-auc:0.77647\teval-logloss:0.36402\ttrain-auc:0.83423\ttrain-logloss:0.33722\n",
      "[109]\teval-auc:0.77641\teval-logloss:0.36399\ttrain-auc:0.83481\ttrain-logloss:0.33685\n",
      "[110]\teval-auc:0.77630\teval-logloss:0.36404\ttrain-auc:0.83517\ttrain-logloss:0.33667\n",
      "[111]\teval-auc:0.77626\teval-logloss:0.36403\ttrain-auc:0.83551\ttrain-logloss:0.33646\n",
      "[112]\teval-auc:0.77614\teval-logloss:0.36407\ttrain-auc:0.83582\ttrain-logloss:0.33625\n",
      "[113]\teval-auc:0.77611\teval-logloss:0.36409\ttrain-auc:0.83589\ttrain-logloss:0.33620\n",
      "[114]\teval-auc:0.77613\teval-logloss:0.36406\ttrain-auc:0.83636\ttrain-logloss:0.33599\n",
      "[115]\teval-auc:0.77602\teval-logloss:0.36407\ttrain-auc:0.83661\ttrain-logloss:0.33582\n",
      "[116]\teval-auc:0.77594\teval-logloss:0.36409\ttrain-auc:0.83718\ttrain-logloss:0.33556\n",
      "[117]\teval-auc:0.77599\teval-logloss:0.36408\ttrain-auc:0.83827\ttrain-logloss:0.33508\n",
      "[118]\teval-auc:0.77596\teval-logloss:0.36409\ttrain-auc:0.83839\ttrain-logloss:0.33500\n",
      "[119]\teval-auc:0.77594\teval-logloss:0.36408\ttrain-auc:0.83873\ttrain-logloss:0.33479\n",
      "[120]\teval-auc:0.77600\teval-logloss:0.36401\ttrain-auc:0.83901\ttrain-logloss:0.33457\n",
      "[121]\teval-auc:0.77602\teval-logloss:0.36402\ttrain-auc:0.83929\ttrain-logloss:0.33435\n",
      "[122]\teval-auc:0.77600\teval-logloss:0.36403\ttrain-auc:0.83981\ttrain-logloss:0.33407\n",
      "[123]\teval-auc:0.77598\teval-logloss:0.36398\ttrain-auc:0.84025\ttrain-logloss:0.33380\n",
      "[124]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84039\ttrain-logloss:0.33371\n",
      "[125]\teval-auc:0.77597\teval-logloss:0.36396\ttrain-auc:0.84091\ttrain-logloss:0.33339\n",
      "[126]\teval-auc:0.77587\teval-logloss:0.36400\ttrain-auc:0.84114\ttrain-logloss:0.33324\n",
      "[127]\teval-auc:0.77600\teval-logloss:0.36395\ttrain-auc:0.84157\ttrain-logloss:0.33296\n",
      "[128]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84160\ttrain-logloss:0.33293\n",
      "[129]\teval-auc:0.77593\teval-logloss:0.36400\ttrain-auc:0.84186\ttrain-logloss:0.33277\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_name = \"xgBoost\"\n",
    "xgb_data_train = dctr_train\n",
    "df_xgb_train =  xgb.DMatrix(xgb_data_train[dense_feature], \n",
    "                            label=xgb_data_train[target])\n",
    "\n",
    "xgb_data_test1 = dctr_v1\n",
    "df_xgb_test1 = xgb.DMatrix(xgb_data_test1[dense_feature],\n",
    "                            label=xgb_data_test1[target])\n",
    "\n",
    "params = {'objective': 'binary:logistic',\n",
    "          'eval_metric': ['auc', 'logloss'],\n",
    "          'learning_rate': 0.06,\n",
    "          'num_leaves':256,\n",
    "          'max_depth':7,\n",
    "          'max_bin':64}\n",
    "\n",
    "evallist = [(df_xgb_test1, 'eval'), (df_xgb_train, 'train')]\n",
    "num_boost_round = 130\n",
    "xgb = xgb.train(params,\n",
    "                df_xgb_train,\n",
    "                num_boost_round,\n",
    "                evallist) \n",
    "\n",
    "xgb_pred_v1 = xgb.predict(df_xgb_test1)\n",
    "xgb_label_v1 = xgb_data_test1[target]\n",
    "auc_t1 = roc_auc_score(xgb_label_v1, xgb_pred_v1)\n",
    "logloss_t1 = log_loss(xgb_label_v1, xgb_pred_v1)\n",
    "res = {'eval_auc':auc_t1, \"eval_logloss\":logloss_t1}\n",
    "\n",
    "results[model_name] = xgb, res, xgb_pred_v1, xgb_label_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "The Deep Neural Network is used as the first baseline taking both dense features and embedding of sparse id features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 59.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 92.25it/s]\n",
      "7it [00:00, 67.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1s - loss:  7.3257 - auc:  0.5278 - logloss:  0.4861 - val_auc:  0.6165 - val_logloss:  0.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.73it/s]\n",
      "7it [00:00, 67.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "1s - loss:  7.2642 - auc:  0.6431 - logloss:  0.4250 - val_auc:  0.6737 - val_logloss:  0.4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.60it/s]\n",
      "7it [00:00, 67.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1s - loss:  7.2522 - auc:  0.6827 - logloss:  0.4130 - val_auc:  0.6969 - val_logloss:  0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.01it/s]\n",
      "7it [00:00, 67.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "1s - loss:  7.2452 - auc:  0.7044 - logloss:  0.4058 - val_auc:  0.7109 - val_logloss:  0.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.08it/s]\n",
      "7it [00:00, 68.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "1s - loss:  7.2395 - auc:  0.7190 - logloss:  0.4001 - val_auc:  0.7221 - val_logloss:  0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.26it/s]\n",
      "7it [00:00, 68.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "1s - loss:  7.2347 - auc:  0.7288 - logloss:  0.3954 - val_auc:  0.7309 - val_logloss:  0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.26it/s]\n",
      "7it [00:00, 67.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "1s - loss:  7.2311 - auc:  0.7377 - logloss:  0.3917 - val_auc:  0.7375 - val_logloss:  0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 88.23it/s]\n",
      "7it [00:00, 67.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "1s - loss:  7.2283 - auc:  0.7421 - logloss:  0.3890 - val_auc:  0.7418 - val_logloss:  0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.00it/s]\n",
      "7it [00:00, 67.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "1s - loss:  7.2263 - auc:  0.7466 - logloss:  0.3871 - val_auc:  0.7454 - val_logloss:  0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.14it/s]\n",
      "7it [00:00, 67.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "1s - loss:  7.2250 - auc:  0.7492 - logloss:  0.3857 - val_auc:  0.7482 - val_logloss:  0.3847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.25it/s]\n",
      "7it [00:00, 67.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "1s - loss:  7.2238 - auc:  0.7509 - logloss:  0.3845 - val_auc:  0.7502 - val_logloss:  0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.15it/s]\n",
      "7it [00:00, 67.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "1s - loss:  7.2227 - auc:  0.7529 - logloss:  0.3836 - val_auc:  0.7518 - val_logloss:  0.3828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.08it/s]\n",
      "7it [00:00, 67.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "1s - loss:  7.2219 - auc:  0.7547 - logloss:  0.3827 - val_auc:  0.7543 - val_logloss:  0.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.87it/s]\n",
      "7it [00:00, 67.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "1s - loss:  7.2211 - auc:  0.7565 - logloss:  0.3816 - val_auc:  0.7553 - val_logloss:  0.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.05it/s]\n",
      "7it [00:00, 67.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "1s - loss:  7.2203 - auc:  0.7579 - logloss:  0.3811 - val_auc:  0.7565 - val_logloss:  0.3803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.13it/s]\n",
      "7it [00:00, 68.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "1s - loss:  7.2195 - auc:  0.7598 - logloss:  0.3803 - val_auc:  0.7577 - val_logloss:  0.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.20it/s]\n",
      "7it [00:00, 68.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "1s - loss:  7.2188 - auc:  0.7599 - logloss:  0.3795 - val_auc:  0.7589 - val_logloss:  0.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 93.94it/s]\n",
      "7it [00:00, 67.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "1s - loss:  7.2184 - auc:  0.7620 - logloss:  0.3792 - val_auc:  0.7594 - val_logloss:  0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.98it/s]\n",
      "7it [00:00, 67.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "1s - loss:  7.2177 - auc:  0.7622 - logloss:  0.3786 - val_auc:  0.7606 - val_logloss:  0.3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 93.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "1s - loss:  7.2171 - auc:  0.7636 - logloss:  0.3779 - val_auc:  0.7618 - val_logloss:  0.3775\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DNN'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=[], \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDL\n",
    "Wide and Deep model [3] is widely accepted in real industrial applications. Compared with DNN, it has an additional linear model besides the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 52.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 76.50it/s]\n",
      "6it [00:00, 55.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss:  7.3530 - auc:  0.5151 - logloss:  0.5117 - val_auc:  0.6197 - val_logloss:  0.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.37it/s]\n",
      "6it [00:00, 55.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "2s - loss:  7.2607 - auc:  0.6692 - logloss:  0.4193 - val_auc:  0.6896 - val_logloss:  0.4106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 77.57it/s]\n",
      "6it [00:00, 55.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "2s - loss:  7.2444 - auc:  0.7211 - logloss:  0.4031 - val_auc:  0.7160 - val_logloss:  0.4015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.17it/s]\n",
      "6it [00:00, 55.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "2s - loss:  7.2348 - auc:  0.7429 - logloss:  0.3937 - val_auc:  0.7300 - val_logloss:  0.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.47it/s]\n",
      "6it [00:00, 55.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2s - loss:  7.2280 - auc:  0.7573 - logloss:  0.3865 - val_auc:  0.7389 - val_logloss:  0.3906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.48it/s]\n",
      "6it [00:00, 56.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "2s - loss:  7.2228 - auc:  0.7659 - logloss:  0.3815 - val_auc:  0.7452 - val_logloss:  0.3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.54it/s]\n",
      "6it [00:00, 56.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "2s - loss:  7.2187 - auc:  0.7714 - logloss:  0.3774 - val_auc:  0.7506 - val_logloss:  0.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.61it/s]\n",
      "6it [00:00, 56.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "2s - loss:  7.2158 - auc:  0.7768 - logloss:  0.3744 - val_auc:  0.7539 - val_logloss:  0.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.63it/s]\n",
      "6it [00:00, 56.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "2s - loss:  7.2134 - auc:  0.7800 - logloss:  0.3720 - val_auc:  0.7569 - val_logloss:  0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 74.26it/s]\n",
      "6it [00:00, 56.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "2s - loss:  7.2115 - auc:  0.7837 - logloss:  0.3702 - val_auc:  0.7590 - val_logloss:  0.3790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 77.57it/s]\n",
      "6it [00:00, 56.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "2s - loss:  7.2099 - auc:  0.7861 - logloss:  0.3688 - val_auc:  0.7606 - val_logloss:  0.3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 77.92it/s]\n",
      "6it [00:00, 55.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "2s - loss:  7.2084 - auc:  0.7887 - logloss:  0.3671 - val_auc:  0.7622 - val_logloss:  0.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 77.50it/s]\n",
      "6it [00:00, 56.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2s - loss:  7.2073 - auc:  0.7902 - logloss:  0.3663 - val_auc:  0.7642 - val_logloss:  0.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.06it/s]\n",
      "6it [00:00, 55.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2s - loss:  7.2059 - auc:  0.7930 - logloss:  0.3647 - val_auc:  0.7651 - val_logloss:  0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.77it/s]\n",
      "6it [00:00, 55.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "2s - loss:  7.2049 - auc:  0.7941 - logloss:  0.3635 - val_auc:  0.7661 - val_logloss:  0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.32it/s]\n",
      "6it [00:00, 55.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2s - loss:  7.2039 - auc:  0.7961 - logloss:  0.3629 - val_auc:  0.7675 - val_logloss:  0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.48it/s]\n",
      "6it [00:00, 55.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2s - loss:  7.2030 - auc:  0.7978 - logloss:  0.3618 - val_auc:  0.7683 - val_logloss:  0.3735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.06it/s]\n",
      "6it [00:00, 55.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "2s - loss:  7.2020 - auc:  0.7985 - logloss:  0.3608 - val_auc:  0.7688 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.48it/s]\n",
      "6it [00:00, 55.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2s - loss:  7.2009 - auc:  0.8016 - logloss:  0.3596 - val_auc:  0.7704 - val_logloss:  0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "2s - loss:  7.1995 - auc:  0.8037 - logloss:  0.3582 - val_auc:  0.7716 - val_logloss:  0.3717\n"
     ]
    }
   ],
   "source": [
    "model_name = 'WDL'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=linear_feature_columns, \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN\n",
    "Deep Interest Network [4] is an attention-based model in recommendation systems that has been proven successful in Alibaba. We use this as our second baseline, replacing the user’s historical item sequences with user’s historical voucher sequences to adapt to the VRR prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7763/46361 [00:00<00:00, 77626.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 80319.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 78355.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 16) \n",
    "                            for feat in ['session_id','user_gender','user_age_level','user_purchase_level', 'promotion_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=16), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (session_id): Embedding(58052, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DIN'\n",
    "\n",
    "model = DIN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "model.embedding_dict['promotion_id'].requires_grad = True\n",
    "model.embedding_dict['promotion_id'].weight.requires_grad = True\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = True\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = True\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:07, 19.65it/s]\n",
      "4it [00:00, 33.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 8\n",
      "8s - loss:  0.4631 - auc:  0.6259 - logloss:  0.4623 - val_auc:  0.7115 - val_logloss:  0.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.41it/s]\n",
      "4it [00:00, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3941 - auc:  0.7297 - logloss:  0.3935 - val_auc:  0.7460 - val_logloss:  0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.29it/s]\n",
      "4it [00:00, 33.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3812 - auc:  0.7582 - logloss:  0.3805 - val_auc:  0.7515 - val_logloss:  0.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.33it/s]\n",
      "4it [00:00, 33.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3740 - auc:  0.7717 - logloss:  0.3731 - val_auc:  0.7624 - val_logloss:  0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.37it/s]\n",
      "4it [00:00, 33.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3699 - auc:  0.7787 - logloss:  0.3694 - val_auc:  0.7699 - val_logloss:  0.3720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 46.14it/s]\n",
      "4it [00:00, 32.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3645 - auc:  0.7884 - logloss:  0.3641 - val_auc:  0.7714 - val_logloss:  0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.93it/s]\n",
      "4it [00:00, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3598 - auc:  0.7951 - logloss:  0.3597 - val_auc:  0.7755 - val_logloss:  0.3698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.77it/s]\n",
      "4it [00:00, 32.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3562 - auc:  0.8005 - logloss:  0.3560 - val_auc:  0.7724 - val_logloss:  0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.85it/s]\n",
      "4it [00:00, 35.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3524 - auc:  0.8065 - logloss:  0.3522 - val_auc:  0.7746 - val_logloss:  0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.95it/s]\n",
      "4it [00:00, 33.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3479 - auc:  0.8124 - logloss:  0.3476 - val_auc:  0.7734 - val_logloss:  0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 45.81it/s]\n",
      "4it [00:00, 33.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3442 - auc:  0.8187 - logloss:  0.3440 - val_auc:  0.7773 - val_logloss:  0.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.78it/s]\n",
      "4it [00:00, 32.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3393 - auc:  0.8260 - logloss:  0.3392 - val_auc:  0.7730 - val_logloss:  0.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.77it/s]\n",
      "4it [00:00, 31.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3329 - auc:  0.8339 - logloss:  0.3329 - val_auc:  0.7692 - val_logloss:  0.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.99it/s]\n",
      "3it [00:00, 27.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3209 - auc:  0.8503 - logloss:  0.3210 - val_auc:  0.7616 - val_logloss:  0.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.91it/s]\n",
      "4it [00:00, 31.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3037 - auc:  0.8708 - logloss:  0.3035 - val_auc:  0.7554 - val_logloss:  0.3970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.75it/s]\n",
      "4it [00:00, 31.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2667 - auc:  0.9058 - logloss:  0.2664 - val_auc:  0.7507 - val_logloss:  0.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 46.42it/s]\n",
      "4it [00:00, 32.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2000 - auc:  0.9476 - logloss:  0.1997 - val_auc:  0.7271 - val_logloss:  0.5144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.00it/s]\n",
      "4it [00:00, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.1159 - auc:  0.9802 - logloss:  0.1157 - val_auc:  0.7174 - val_logloss:  0.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.98it/s]\n",
      "4it [00:00, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0558 - auc:  0.9949 - logloss:  0.0556 - val_auc:  0.7151 - val_logloss:  0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0262 - auc:  0.9986 - logloss:  0.0261 - val_auc:  0.7182 - val_logloss:  inf\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Method: DMBGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-AvgPooling\n",
    "Instead of using Higher-order Graph Neural Networks to model user-voucher-item relationships, it directly takes an average of pre-trained item embeddings from user behavior happening both before and after voucher collection. For target UVG, it only takes an average of pre-collection item embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286735it [00:28, 10164.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_pretrain_emb(emb, emb_size = 16, spliter = \" \"):\n",
    "    return np.zeros(emb_size, dtype=np.float32) if emb == 'nan' else np.array(emb.split(spliter), dtype=np.float32)\n",
    "\n",
    "item_df[['atc_emb', 'ord_emb']] = item_df[['atc_emb', 'ord_emb']].astype('str')\n",
    "item_emb_dict = {}\n",
    "for index, row in tqdm(item_df.iterrows()):\n",
    "    item_emb_dict[row['item_id']] = process_pretrain_emb(row['atc_emb']), process_pretrain_emb(row['ord_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1118593it [01:39, 11246.41it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 111373.08it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 281793.64it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_size = 16\n",
    "sid_emb_dict_tmp = {}\n",
    "\n",
    "session_df['sid_enc'] = label_encoder['session_id'].transform(session_df['session_id'])\n",
    "\n",
    "for index, row in tqdm(session_df.iterrows()):\n",
    "    sid = row['sid_enc']\n",
    "    if sid not in sid_emb_dict_tmp:\n",
    "        sid_emb_dict_tmp[row['sid_enc']] = np.zeros(emb_size, dtype=np.float32), np.zeros(emb_size, dtype=np.float32), 0, 0\n",
    "    \n",
    "    if row['rk'] > 6:\n",
    "        continue\n",
    "    \n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = sid_emb_dict_tmp.get(sid)\n",
    "    item_atc_emb, item_ord_emb = item_emb_dict.get(row['item_id'])\n",
    "    if row['type'] == 'bef':\n",
    "        emb_bef += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_bef += 1\n",
    "    else:\n",
    "        emb_aft += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_aft += 1\n",
    "    sid_emb_dict_tmp[sid] = emb_bef, emb_aft, cnt_bef, cnt_aft\n",
    "\n",
    "sid_emb_dict = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict[sid] = np.concatenate((emb_bef/(1.0*cnt_bef), emb_aft/(1.0*cnt_aft)), axis=0)\n",
    "\n",
    "sid_emb_dict_bef = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict_bef[sid] = emb_bef/(1.0*cnt_bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_emb_ts(emb_dic, requires_grad = False, emb_size = 16, lbe = None):\n",
    "    if lbe is None:\n",
    "        raise Exception(\"Encoder is empty\")\n",
    "        \n",
    "    indices = lbe.transform([str(val) for val in emb_dic.keys()])\n",
    "    session_size = int(len(lbe))\n",
    "    \n",
    "    ts_emb = torch.rand(session_size, emb_size, dtype = torch.float)\n",
    "    for i, (key, emb) in tqdm(enumerate(emb_dic.items())):\n",
    "        ts_emb[indices[i]] = torch.FloatTensor(emb)\n",
    "    emb_ts = torch.nn.Embedding.from_pretrained(ts_emb)\n",
    "    emb_ts.weight.requires_grad = requires_grad\n",
    "    return emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58052it [00:00, 67667.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(58052, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_emb_ts = init_emb_ts(sid_emb_dict, emb_size = 32, lbe=label_encoder['session_id'])\n",
    "sid_emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['session_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim2) for feat in ['promotion_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['session_id']), embedding_dim = embedding_dim1) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_session_id', len(label_encoder[\"session_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'session_id']\n",
    "    dataset['sid'] = dataset['session_id']\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    x['session_id'] = x['promotion_id']\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 7590/46361 [00:00<00:00, 75894.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 77356.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 16108/46361 [00:00<00:00, 78962.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 78532.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 74957.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11690/11690 [00:00<00:00, 76763.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = sid_emb_ts.weight.shape[1] #sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (session_id): Embedding(462, 32)\n",
       "    (promotion_id): Embedding(462, 32)\n",
       "    (sid): Embedding(58052, 16)\n",
       "    (hist_promotion_id): Embedding(462, 32)\n",
       "    (hist_session_id): Embedding(58052, 32)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_AvgPooling'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "model.embedding_dict['hist_session_id'] = sid_emb_ts\n",
    "model.embedding_dict['hist_session_id'].requires_grad = False\n",
    "model.embedding_dict['hist_session_id'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.08it/s]\n",
      "3it [00:00, 27.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5773 - auc:  0.6206 - logloss:  0.4644 - val_auc:  0.7242 - val_logloss:  0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.12it/s]\n",
      "3it [00:00, 28.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4841 - auc:  0.7438 - logloss:  0.3881 - val_auc:  0.7498 - val_logloss:  0.3837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.78it/s]\n",
      "3it [00:00, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4673 - auc:  0.7636 - logloss:  0.3788 - val_auc:  0.7599 - val_logloss:  0.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.61it/s]\n",
      "3it [00:00, 28.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4527 - auc:  0.7742 - logloss:  0.3713 - val_auc:  0.7699 - val_logloss:  0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.54it/s]\n",
      "3it [00:00, 24.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4467 - auc:  0.7809 - logloss:  0.3685 - val_auc:  0.7726 - val_logloss:  0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.47it/s]\n",
      "3it [00:00, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4413 - auc:  0.7869 - logloss:  0.3645 - val_auc:  0.7740 - val_logloss:  0.3698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.21it/s]\n",
      "3it [00:00, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4361 - auc:  0.7935 - logloss:  0.3612 - val_auc:  0.7729 - val_logloss:  0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.12it/s]\n",
      "3it [00:00, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4304 - auc:  0.7978 - logloss:  0.3585 - val_auc:  0.7737 - val_logloss:  0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.96it/s]\n",
      "3it [00:00, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4247 - auc:  0.8038 - logloss:  0.3550 - val_auc:  0.7719 - val_logloss:  0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.42it/s]\n",
      "3it [00:00, 27.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4215 - auc:  0.8065 - logloss:  0.3521 - val_auc:  0.7789 - val_logloss:  0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.31it/s]\n",
      "3it [00:00, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4179 - auc:  0.8113 - logloss:  0.3492 - val_auc:  0.7637 - val_logloss:  0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.26it/s]\n",
      "3it [00:00, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4157 - auc:  0.8150 - logloss:  0.3469 - val_auc:  0.7705 - val_logloss:  0.3724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.30it/s]\n",
      "3it [00:00, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4098 - auc:  0.8235 - logloss:  0.3413 - val_auc:  0.7742 - val_logloss:  0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.61it/s]\n",
      "3it [00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4048 - auc:  0.8313 - logloss:  0.3363 - val_auc:  0.7697 - val_logloss:  0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.61it/s]\n",
      "3it [00:00, 28.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3963 - auc:  0.8419 - logloss:  0.3279 - val_auc:  0.7627 - val_logloss:  0.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.35it/s]\n",
      "3it [00:00, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3804 - auc:  0.8631 - logloss:  0.3123 - val_auc:  0.7557 - val_logloss:  0.4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.34it/s]\n",
      "3it [00:00, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3442 - auc:  0.9003 - logloss:  0.2759 - val_auc:  0.7319 - val_logloss:  0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.17it/s]\n",
      "3it [00:00, 27.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.2797 - auc:  0.9469 - logloss:  0.2116 - val_auc:  0.7150 - val_logloss:  0.5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.47it/s]\n",
      "3it [00:00, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.1962 - auc:  0.9805 - logloss:  0.1280 - val_auc:  0.7201 - val_logloss:  0.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.1286 - auc:  0.9946 - logloss:  0.0603 - val_auc:  0.7039 - val_logloss:  0.8777\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-Pretrained\n",
    "It uses the same weight parameters of Higher-order GNN learned during the voucher embedding pre-training as mentioned in Section 3.3. The values of weight parameters are not further updated during the main task training for DMBGN-Pretrained variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>session_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount_amount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>item_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>type</th>\n",
       "      <th>rk</th>\n",
       "      <th>action_time</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_brand_id</th>\n",
       "      <th>item_price_level</th>\n",
       "      <th>sid_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85356</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>12</td>\n",
       "      <td>6874</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85352</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>11</td>\n",
       "      <td>6850</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85351</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>10</td>\n",
       "      <td>6838</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>92250</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>9</td>\n",
       "      <td>6871</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>88965</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>8</td>\n",
       "      <td>6838</td>\n",
       "      <td>2272</td>\n",
       "      <td>106903</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118588</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>19882</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>3</td>\n",
       "      <td>129021</td>\n",
       "      <td>12057</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118589</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>1333</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>4</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118590</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>65011</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>5</td>\n",
       "      <td>129021</td>\n",
       "      <td>12141</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118591</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>18048</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>6</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118592</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>8252</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>7</td>\n",
       "      <td>129021</td>\n",
       "      <td>6505</td>\n",
       "      <td>56645</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118593 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  session_id promotion_id  voucher_min_spend  \\\n",
       "0            0        9180           20               4999   \n",
       "1            0        9180           20               4999   \n",
       "2            0        9180           20               4999   \n",
       "3            0        9180           20               4999   \n",
       "4            0        9180           20               4999   \n",
       "...        ...         ...          ...                ...   \n",
       "1118588      0       17339          310                349   \n",
       "1118589      0       17339          310                349   \n",
       "1118590      0       17339          310                349   \n",
       "1118591      0       17339          310                349   \n",
       "1118592      0       17339          310                349   \n",
       "\n",
       "         voucher_discount_amount voucher_collect_time item_id action_type  \\\n",
       "0                            600                10999   85356        cart   \n",
       "1                            600                10999   85352        cart   \n",
       "2                            600                10999   85351        cart   \n",
       "3                            600                10999   92250        cart   \n",
       "4                            600                10999   88965        cart   \n",
       "...                          ...                  ...     ...         ...   \n",
       "1118588                       30               119218   19882       order   \n",
       "1118589                       30               119218    1333       order   \n",
       "1118590                       30               119218   65011       order   \n",
       "1118591                       30               119218   18048       order   \n",
       "1118592                       30               119218    8252       order   \n",
       "\n",
       "        type  rk action_time  item_category_id  item_brand_id  \\\n",
       "0        bef  12        6874              9567         106903   \n",
       "1        bef  11        6850              9567         106903   \n",
       "2        bef  10        6838              9567         106903   \n",
       "3        bef   9        6871              9567         106903   \n",
       "4        bef   8        6838              2272         106903   \n",
       "...      ...  ..         ...               ...            ...   \n",
       "1118588  aft   3      129021             12057          56645   \n",
       "1118589  aft   4      129021             13895          56645   \n",
       "1118590  aft   5      129021             12141          56645   \n",
       "1118591  aft   6      129021             13895          56645   \n",
       "1118592  aft   7      129021              6505          56645   \n",
       "\n",
       "         item_price_level  sid_enc  \n",
       "0                     7.0     8998  \n",
       "1                     7.0     8998  \n",
       "2                     7.0     8998  \n",
       "3                     7.0     8998  \n",
       "4                     5.0     8998  \n",
       "...                   ...      ...  \n",
       "1118588               1.0    16986  \n",
       "1118589               2.0    16986  \n",
       "1118590               2.0    16986  \n",
       "1118591               1.0    16986  \n",
       "1118592               3.0    16986  \n",
       "\n",
       "[1118593 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_session_df = session_df.copy()\n",
    "sid_lbe = LabelEncoderExt()\n",
    "gnn_session_df['session_id'] = sid_lbe.fit_transform(gnn_session_df['session_id'])\n",
    "gnn_session_df = gnn_session_df.fillna(0)\n",
    "gnn_session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UVG Graphs\n",
    "load the related UVG network into the InMemoryDataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [15:18<00:00, 67.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch_geometric.data.dataloader.DataLoader at 0x2ae27ad7b490>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 512\n",
    "\n",
    "geometric_data_path = './data/voucher_geometric/'\n",
    "processed_file_name = 'graph_cache'\n",
    "gnn_dat = VoucherGraphDataset(root=geometric_data_path, processed_file_name=processed_file_name, gnn_session_df=gnn_session_df)\n",
    "\n",
    "data_loader = DataLoader(gnn_dat, batch_size=batch_size)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Networks\n",
    "In this section, we first define the User-behavior Voucher Graph (UVG) network with VoucherGraphNet, training the network with loaded dataset data_loader with VoucherGraphDataset and output the generated UVG embedding $e_{UVG}$ with UVG score $s_{UVG}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Pretrained Item Embeddings\n",
    "load the pretrinaed embedding results for atc/ord item into the embedding tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286735/286735 [00:16<00:00, 17518.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(344082, 16), Embedding(344082, 16))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_size = int(len(item_df) * 1.2)\n",
    "emb_size = 16\n",
    "atc_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "ord_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "\n",
    "for i in tqdm(range(len(item_df))):\n",
    "    item_id = int(item_df['item_id'][i])\n",
    "    idx = hash_func(item_id, item_size)\n",
    "    \n",
    "    if pd.isna(item_df['atc_emb'][i]) is False and len(item_df['atc_emb'][i].split(' ')) > 3:\n",
    "        atc_emb = [float(val) for val in item_df['atc_emb'][i].split(' ')]\n",
    "        atc_emb_ts[idx] = torch.FloatTensor(atc_emb)\n",
    "    \n",
    "    if pd.isna(item_df['ord_emb'][i]) is False and len(item_df['ord_emb'][i].split(' ')) > 3:\n",
    "        ord_emb = [float(val) for val in item_df['ord_emb'][i].split(' ')]\n",
    "        ord_emb_ts[idx] = torch.FloatTensor(ord_emb) \n",
    "        \n",
    "atc_emb_ts = torch.nn.Embedding.from_pretrained(atc_emb_ts)\n",
    "atc_emb_ts.weight.requires_grad = False\n",
    "ord_emb_ts = torch.nn.Embedding.from_pretrained(ord_emb_ts) \n",
    "ord_emb_ts.weight.requires_grad = False\n",
    "\n",
    "atc_emb_ts, ord_emb_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN\n",
    "train the UVG Graph with Higher-order GNN, the AUC output here repesents the AUC performance using only GNN network, which can be considered as another ablation study. The trained GNN is saved in the ./data/gnet.pretrained_{epochs}.bin file to be loaded for fine-tune later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = ['item_id', 'item_category_id', 'item_brand_id', 'item_price_level']\n",
    "promotion_features = ['promotion_id', 'session_id', 'voucher_min_spend', 'voucher_discount_amount']\n",
    "all_features = item_features + promotion_features + ['action_type', 'label']\n",
    "\n",
    "after_prefix = 'a_'\n",
    "before_prefix = 'b_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 25/122 [04:21<17:10, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[25] - auc 0.5098590160701961; loss 0.5881080031394958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 50/122 [08:38<11:43,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[50] - auc 0.5390803307516744; loss 0.4756115972995758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 75/122 [12:43<07:32,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[75] - auc 0.5889131489568171; loss 0.39700013399124146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 100/122 [16:39<03:27,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[100] - auc 0.6827335858585859; loss 0.4064457416534424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [19:58<00:00,  9.83s/it]\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/122 [00:31<20:32, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[125] - auc 0.7065954539808719; loss 0.4557380676269531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 28/122 [04:51<16:12, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[150] - auc 0.6814671272502597; loss 0.43105316162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 53/122 [09:06<11:09,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[175] - auc 0.6874337601329094; loss 0.43508458137512207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 78/122 [13:10<07:03,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[200] - auc 0.7553992348512897; loss 0.37773483991622925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 103/122 [17:04<02:54,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[225] - auc 0.7355014463448198; loss 0.40350326895713806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [19:55<00:00,  9.80s/it]\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/122 [01:02<20:20, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[250] - auc 0.680890999547716; loss 0.4961029589176178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 31/122 [05:22<15:56, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[275] - auc 0.6300832194758414; loss 0.489351749420166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 56/122 [09:35<10:42,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[300] - auc 0.7524388936535163; loss 0.4194798171520233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 81/122 [13:38<06:33,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[325] - auc 0.7347334042229987; loss 0.33465683460235596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 106/122 [17:29<02:20,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[350] - auc 0.7515558467081559; loss 0.3907470405101776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [19:55<00:00,  9.80s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "emb_info = {\n",
    "    'item_category_id': (6000, 1),\n",
    "    'item_price_level': (300, 1),\n",
    "    'promotion_id': (600, int(atc_emb_ts.weight.shape[1])),\n",
    "    'voucher_min_spend': (500, 1),\n",
    "    'voucher_discount_amount': (500, 1),\n",
    "}\n",
    "\n",
    "emb_dict = {\n",
    "    'atc': atc_emb_ts,\n",
    "    'ord': ord_emb_ts,\n",
    "}\n",
    "\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'],\n",
    "                       device=device)\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(gnet.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "epochs = 3\n",
    "gnn_file = './data/gnet.pretrained_{epochs}.bin'.format(epochs=epochs)\n",
    "\n",
    "train_ready = True if os.path.exists(gnn_file) else False\n",
    "\n",
    "if train_ready is False:\n",
    "    gstep = 0\n",
    "    gnet.train()\n",
    "    loader_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"# Epoch - {epoch}\".format(epoch=epoch))\n",
    "        try:\n",
    "            for dat in tqdm(data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                graph_dicts = dat.graph_dict\n",
    "                out = None\n",
    "                valid_list = []\n",
    "                gstep += 1\n",
    "                for graph_dict in graph_dicts:\n",
    "                    res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "                    if res is None or torch.isnan(res):\n",
    "                        valid_list.append(False)\n",
    "                        continue\n",
    "                    valid_list.append(True)\n",
    "                    out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "                pred = out.cpu()\n",
    "                lbe = dat.label.cpu()[valid_list]\n",
    "                loss = crit(pred, lbe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if gstep % 25 == 0:\n",
    "                    auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "                    print('GNN[{gstep}] - auc {auc}; loss {loss}'.format(auc=auc ,gstep=gstep ,loss=loss))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    torch.save(gnet.state_dict(), gnn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoucherGraphNet(\n",
       "  (emb_dic): ModuleDict(\n",
       "    (atc_emb): Embedding(344082, 16)\n",
       "    (ord_emb): Embedding(344082, 16)\n",
       "    (item_category_id): Embedding(6000, 1)\n",
       "    (item_price_level): Embedding(300, 1)\n",
       "    (promotion_id): Embedding(600, 16)\n",
       "    (voucher_min_spend): Embedding(500, 1)\n",
       "    (voucher_discount_amount): Embedding(500, 1)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): GraphConv(18, 16)\n",
       "    (1): GraphConv(16, 16)\n",
       "  )\n",
       "  (pools): ModuleList(\n",
       "    (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "  )\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained GNN network parameter\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'], \n",
    "                       device=device)\n",
    "gnet.load_state_dict(torch.load(gnn_file))\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "\n",
    "# Use Before UVG Only\n",
    "gnet_before = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, device=device)\n",
    "gnet_before.load_state_dict(torch.load(gnn_file))\n",
    "gnet_before = gnet_before.float().to(device)\n",
    "gnet_before.gprefix = [before_prefix, 'unknown'] \n",
    "\n",
    "gnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pretrained UVG Embeddings\n",
    "generate pretrained embeddings from UVG network for each UVG. Note here we have gnet and gnet_before which represents UVG including both 'bef' and 'aft' user behaviors and including 'bef' user behaviors only. From the AUC performance output we see that gnet has better performance than gnet_before, which indicates the importance of taking 'aft' user behaviors into consideration. This can be considered as another ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gstep = 1; auc = 0.7167146115189318; loss = 0.4340111315250397; auc_before = 0.5803768340039197 0.5024861097335815\n",
      "gstep = 2; auc = 0.7343798977960506; loss = 0.40651506185531616; auc_before = 0.5919482680416188 0.4862906336784363\n",
      "gstep = 3; auc = 0.755977952869204; loss = 0.35435977578163147; auc_before = 0.6002010714152302 0.45418480038642883\n",
      "gstep = 4; auc = 0.7783587337578577; loss = 0.3566121757030487; auc_before = 0.5878568189048866 0.4580093026161194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [00:00<00:00, 623122.99it/s]\n",
      "100%|██████████| 43989/43989 [00:00<00:00, 788519.19it/s]\n",
      "  0%|          | 0/62068 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gstep = 5; auc = 0.7412623202522659; loss = 0.4386313855648041; auc_before = 0.588513267902581 0.49945828318595886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [00:00<00:00, 849683.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(462, 62068, 43989, 62068)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_protocol = 4\n",
    "\n",
    "gnet.eval()\n",
    "gnet_before.eval()\n",
    "gstep = 0\n",
    "\n",
    "\n",
    "raw_sid_uvg_graphs_dic = {}\n",
    "\n",
    "promotion_emb_dic = {}\n",
    "session_emb_raw_dic = {}\n",
    "session_emb_raw_dic_before = {}\n",
    "\n",
    "gnn_pretrained_emb_file = 'data/gnet.pretrained.{epochs}.emb.pkl'.format(epochs=epochs)\n",
    "\n",
    "gnn_emb_ready = True if os.path.exists(gnn_pretrained_emb_file) else False\n",
    "\n",
    "def hash_func(ts, item_size):\n",
    "    return ts % item_size\n",
    "\n",
    "if gnn_emb_ready is False:\n",
    "    session_emb_dic = {}\n",
    "    sid_uvg_graphs_dic = {}\n",
    "    session_emb_dic_before = {}\n",
    "    for dat in DataLoader(gnn_dat, batch_size=batch_size * 30):\n",
    "        graph_dicts = dat.graph_dict\n",
    "        out = None\n",
    "        out2 = None\n",
    "        valid_list = []\n",
    "        valid_list2 = []\n",
    "        gstep += 1\n",
    "        for graph_dict in graph_dicts :\n",
    "            res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "            res_before, _, _, _, emb_session_id_before = gnet_before(graph_dict)\n",
    "            if res is None or torch.isnan(res):\n",
    "                valid_list.append(False)\n",
    "                continue\n",
    "\n",
    "            valid_list.append(True)\n",
    "            out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "            promotion_emb_dic[promotion_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_promotion.cpu().detach().numpy()\n",
    "            session_emb_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id.cpu().detach().numpy()\n",
    "            sid_uvg_graphs_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = graph_dict\n",
    "            \n",
    "            if res_before is not None or torch.isnan(res) is False:\n",
    "                session_emb_dic_before[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id_before.cpu().detach().numpy()\n",
    "                out2 = res_before if out2 is None else torch.cat([out2, res_before], dim=0)\n",
    "                valid_list2.append(True)\n",
    "            else :\n",
    "                valid_list2.append(False)\n",
    "\n",
    "        try:\n",
    "            lbe = dat.label.cpu()[valid_list]\n",
    "            lbe2 = dat.label.cpu()[valid_list2]\n",
    "            pred = out.cpu()\n",
    "            pred2 = out2.cpu()\n",
    "            loss = crit(pred, lbe)\n",
    "            loss2 = crit(pred2, lbe2)\n",
    "            auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "            auc2 = roc_auc_score(lbe2.detach().numpy().ravel(), pred2.detach().numpy().ravel())\n",
    "            print(\"gstep = {gstep}; auc = {auc}; loss = {loss}; auc_before = {auc2} {loss2}\".format(gstep=gstep,\n",
    "                                                                                                    auc=auc, \n",
    "                                                                                                    loss2=loss2,\n",
    "                                                                                                    auc2 =auc2,\n",
    "                                                                                                    loss=loss))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for key, emb in tqdm(session_emb_dic.items()):\n",
    "        session_emb_raw_dic[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    # session_emb_raw_dic_before use for target session id with no after behaviors know beforehand\n",
    "    for key, emb in tqdm(session_emb_dic_before.items()):\n",
    "        session_emb_raw_dic_before[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    for key, uvg in tqdm(sid_uvg_graphs_dic.items()):\n",
    "         raw_sid_uvg_graphs_dic[sid_lbe.label_encoder.classes_[key]] = uvg\n",
    "        \n",
    "    with open(gnn_pretrained_emb_file, 'wb') as f:\n",
    "        pickle.dump(promotion_emb_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic_before, f, pickle_protocol)\n",
    "        pickle.dump(raw_sid_uvg_graphs_dic, f, pickle_protocol)\n",
    "\n",
    "else :\n",
    "    print('loading existing trained embeddings...')\n",
    "    with open(gnn_pretrained_emb_file, \"rb\") as f:\n",
    "        promotion_emb_dic = pickle.load(f)\n",
    "        session_emb_raw_dic = pickle.load(f)\n",
    "        session_emb_raw_dic_before = pickle.load(f)\n",
    "        raw_sid_uvg_graphs_dic = pickle.load(f)\n",
    "        \n",
    "len(promotion_emb_dic), len(session_emb_raw_dic), len(session_emb_raw_dic_before), len(raw_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118593/1118593 [00:17<00:00, 62256.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1118593, 0.7234987068843899, 0.558885262299762)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "labels_before = []\n",
    "scores_before = [] \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "for iii in tqdm(range(len(session_df))):\n",
    "    sid = session_df['session_id'].values[iii]\n",
    "    promotion_id = int(session_df['promotion_id'].values[iii])\n",
    "    label = session_df['label'].values[iii]\n",
    "    \n",
    "    if sid not in session_emb_raw_dic:\n",
    "        continue\n",
    "    \n",
    "    session_emb = session_emb_raw_dic[sid]\n",
    "    promotion_emb = promotion_emb_dic[promotion_id]\n",
    "            \n",
    "    labels.append(label)\n",
    "    score = sigmoid(np.matmul(session_emb, promotion_emb))\n",
    "    scores.append(score)\n",
    "    \n",
    "    if sid in session_emb_raw_dic_before:\n",
    "        session_emb_before = session_emb_raw_dic_before[sid]\n",
    "        score_before = sigmoid(np.matmul(session_emb_before, promotion_emb))\n",
    "        scores_before.append(score_before)\n",
    "        labels_before.append(label)\n",
    "            \n",
    "auc = roc_auc_score(labels, scores)\n",
    "auc_before = roc_auc_score(labels_before, scores_before)\n",
    "len(scores), auc, auc_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DMBGN Log Processing\n",
    "log processing for DMBGN training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df['hist_sid'] = df['hist_session_id']\n",
    "\n",
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_sid','keys_length']\n",
    "\n",
    "ignore_features=['hist_session_id', 'dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    if feat in ignore_features:\n",
    "        continue\n",
    "    if feat not in hist_list_features:\n",
    "        train_features.append(feat)\n",
    "    if feat not in hist_list_features and feat not in sparse_feature:\n",
    "        dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 20:07:02,909 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 20:07:03,157 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2021-06-01 20:07:03,247 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2021-06-01 20:07:03,332 [WARNING]: LabelEncoder encoding user_age_level len 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 20:07:03,418 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "    \n",
    "label_encoder['sid'] = label_encoder['session_id']\n",
    "df['sid'] = df['promotion_id']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]\n",
    "\n",
    "deep_ctr_df = df \n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 7161/46361 [00:00<00:00, 71604.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 74978.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7517/46361 [00:00<00:00, 75169.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 76302.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 73574.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11690/11690 [00:00<00:00, 74101.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:00, 70280.07it/s]\n",
      "462it [00:00, 61563.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (sid): Embedding(462, 16)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "    (hist_sid): Embedding(58052, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_Pretrained'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list,\n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "gnn_fine_tune = False\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16 \n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.40it/s]\n",
      "3it [00:00, 27.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.6773 - auc:  0.6443 - logloss:  0.4527 - val_auc:  0.7235 - val_logloss:  0.3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.91it/s]\n",
      "4it [00:00, 34.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.6125 - auc:  0.7421 - logloss:  0.3877 - val_auc:  0.7450 - val_logloss:  0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.81it/s]\n",
      "3it [00:00, 26.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.6051 - auc:  0.7594 - logloss:  0.3797 - val_auc:  0.7611 - val_logloss:  0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.19it/s]\n",
      "3it [00:00, 27.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5983 - auc:  0.7725 - logloss:  0.3731 - val_auc:  0.7667 - val_logloss:  0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.00it/s]\n",
      "3it [00:00, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5944 - auc:  0.7797 - logloss:  0.3689 - val_auc:  0.7724 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 32.76it/s]\n",
      "3it [00:00, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 5\n",
      "5s - loss:  0.5896 - auc:  0.7872 - logloss:  0.3647 - val_auc:  0.7720 - val_logloss:  0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.61it/s]\n",
      "3it [00:00, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5851 - auc:  0.7941 - logloss:  0.3604 - val_auc:  0.7769 - val_logloss:  0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.98it/s]\n",
      "3it [00:00, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5820 - auc:  0.7997 - logloss:  0.3566 - val_auc:  0.7765 - val_logloss:  0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.49it/s]\n",
      "3it [00:00, 28.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5791 - auc:  0.8037 - logloss:  0.3541 - val_auc:  0.7791 - val_logloss:  0.3680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.72it/s]\n",
      "3it [00:00, 28.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5775 - auc:  0.8085 - logloss:  0.3514 - val_auc:  0.7767 - val_logloss:  0.3713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.83it/s]\n",
      "4it [00:00, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5736 - auc:  0.8118 - logloss:  0.3491 - val_auc:  0.7753 - val_logloss:  0.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.13it/s]\n",
      "3it [00:00, 29.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5703 - auc:  0.8156 - logloss:  0.3460 - val_auc:  0.7778 - val_logloss:  0.3693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.67it/s]\n",
      "3it [00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5679 - auc:  0.8194 - logloss:  0.3431 - val_auc:  0.7764 - val_logloss:  0.3698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.16it/s]\n",
      "3it [00:00, 25.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5648 - auc:  0.8229 - logloss:  0.3404 - val_auc:  0.7783 - val_logloss:  0.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.73it/s]\n",
      "3it [00:00, 26.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5618 - auc:  0.8276 - logloss:  0.3370 - val_auc:  0.7780 - val_logloss:  0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.54it/s]\n",
      "3it [00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5620 - auc:  0.8290 - logloss:  0.3368 - val_auc:  0.7804 - val_logloss:  0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.83it/s]\n",
      "3it [00:00, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5580 - auc:  0.8338 - logloss:  0.3321 - val_auc:  0.7740 - val_logloss:  0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.37it/s]\n",
      "4it [00:00, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5553 - auc:  0.8365 - logloss:  0.3291 - val_auc:  0.7731 - val_logloss:  0.3776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.68it/s]\n",
      "3it [00:00, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5525 - auc:  0.8407 - logloss:  0.3266 - val_auc:  0.7710 - val_logloss:  0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5507 - auc:  0.8424 - logloss:  0.3252 - val_auc:  0.7678 - val_logloss:  0.3847\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN\n",
    "The proposed model in this work, which loads the pre-trained GNN network including the item and voucher node embeddings. The GNN network parameters are further fine-tuned according to the final training loss. \\\n",
    "Note that it might takes a longer time to train DMBGN as it involves the training of GNN network. In our work, we used multiple GPUs to accerlate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7397/46361 [00:00<00:00, 73966.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'session_id', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 74776.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 14358/46361 [00:00<00:00, 71207.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 73460.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 74706.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'session_id', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11690/11690 [00:00<00:00, 74402.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 1) for feat in ['session_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:00, 68825.47it/s]\n",
      "462it [00:00, 59963.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:00, 1294160.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58052"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_sid_uvg_graphs_dic = {}\n",
    "hash_sids = label_encoder['session_id'].transform([str(val) for val in raw_sid_uvg_graphs_dic.keys()])\n",
    "for i, (key, uvgs) in tqdm(enumerate(raw_sid_uvg_graphs_dic.items())):\n",
    "    hash_sid_uvg_graphs_dic[hash_sids[i]] = uvgs\n",
    "\n",
    "len(hash_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (sid): Embedding(462, 16)\n",
       "    (session_id): Embedding(58052, 1)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "    (hist_sid): Embedding(58052, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=130, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  (gnet): VoucherGraphNet(\n",
       "    (emb_dic): ModuleDict(\n",
       "      (atc_emb): Embedding(344082, 16)\n",
       "      (ord_emb): Embedding(344082, 16)\n",
       "      (item_category_id): Embedding(6000, 1)\n",
       "      (item_price_level): Embedding(300, 1)\n",
       "      (promotion_id): Embedding(600, 16)\n",
       "      (voucher_min_spend): Embedding(500, 1)\n",
       "      (voucher_discount_amount): Embedding(500, 1)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphConv(18, 16)\n",
       "      (1): GraphConv(16, 16)\n",
       "    )\n",
       "    (pools): ModuleList(\n",
       "      (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "      (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    )\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gnet_before): VoucherGraphNet(\n",
       "    (emb_dic): ModuleDict(\n",
       "      (atc_emb): Embedding(344082, 16)\n",
       "      (ord_emb): Embedding(344082, 16)\n",
       "      (item_category_id): Embedding(6000, 1)\n",
       "      (item_price_level): Embedding(300, 1)\n",
       "      (promotion_id): Embedding(600, 16)\n",
       "      (voucher_min_spend): Embedding(500, 1)\n",
       "      (voucher_discount_amount): Embedding(500, 1)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphConv(18, 16)\n",
       "      (1): GraphConv(16, 16)\n",
       "    )\n",
       "    (pools): ModuleList(\n",
       "      (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "      (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    )\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "              behavior_feature_list,\n",
    "              target_emb_dim_aft=0, \n",
    "              sequence_size=6,\n",
    "              device=device, \n",
    "              att_activation='prelu', \n",
    "              att_weight_normalization=False, \n",
    "              dnn_activation='relu', \n",
    "              l2_reg_dnn=0.1, \n",
    "              l2_reg_embedding = 0.0001, \n",
    "              dnn_hidden_units=(128,64), \n",
    "              att_hidden_size=(64,), \n",
    "              init_std=1, \n",
    "              dnn_dropout=0.5, \n",
    "              dnn_use_bn=True,\n",
    "              gnet_tune=True,\n",
    "              hist_gnn_dropout=0.6, \n",
    "              gnet=gnet, \n",
    "              gnet_before=gnet_before,\n",
    "              hash_sid_uvg_graphs_dic=hash_sid_uvg_graphs_dic)\n",
    "\n",
    "\n",
    "zeros = torch.zeros(len(label_encoder['session_id']), 1, dtype = torch.float)\n",
    "model.embedding_dict['session_id'] = torch.nn.Embedding.from_pretrained(zeros)\n",
    "model.embedding_dict['session_id'].requires_grad = False\n",
    "model.embedding_dict['session_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = False\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = False\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:05:28, 25.35s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 4597\n",
      "4597s - loss:  0.5805 - auc:  0.6184 - logloss:  0.4968 - val_auc:  0.7170 - val_logloss:  0.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:06:42, 25.82s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 4659\n",
      "4659s - loss:  0.4590 - auc:  0.7346 - logloss:  0.3911 - val_auc:  0.7471 - val_logloss:  0.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:51, 25.11s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 4560\n",
      "4560s - loss:  0.4476 - auc:  0.7557 - logloss:  0.3809 - val_auc:  0.7601 - val_logloss:  0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:06:05, 25.58s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 4621\n",
      "4621s - loss:  0.4408 - auc:  0.7681 - logloss:  0.3748 - val_auc:  0.7708 - val_logloss:  0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:05:09, 25.22s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 4561\n",
      "4561s - loss:  0.4355 - auc:  0.7780 - logloss:  0.3700 - val_auc:  0.7749 - val_logloss:  0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:14, 24.87s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 4511\n",
      "4511s - loss:  0.4313 - auc:  0.7841 - logloss:  0.3657 - val_auc:  0.7765 - val_logloss:  0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:07:05, 25.97s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 4687\n",
      "4687s - loss:  0.4283 - auc:  0.7893 - logloss:  0.3630 - val_auc:  0.7797 - val_logloss:  0.3665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:34, 25.00s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 4538\n",
      "4538s - loss:  0.4257 - auc:  0.7937 - logloss:  0.3600 - val_auc:  0.7809 - val_logloss:  0.3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:22, 24.92s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 4526\n",
      "4526s - loss:  0.4221 - auc:  0.7996 - logloss:  0.3565 - val_auc:  0.7803 - val_logloss:  0.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:18, 24.89s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 4518\n",
      "4518s - loss:  0.4211 - auc:  0.8001 - logloss:  0.3557 - val_auc:  0.7841 - val_logloss:  0.3632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:24, 24.93s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 4523\n",
      "4523s - loss:  0.4191 - auc:  0.8046 - logloss:  0.3535 - val_auc:  0.7882 - val_logloss:  0.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:33, 24.99s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 4517\n",
      "4517s - loss:  0.4172 - auc:  0.8067 - logloss:  0.3518 - val_auc:  0.7825 - val_logloss:  0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:05:41, 25.43s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 4590\n",
      "4590s - loss:  0.4146 - auc:  0.8116 - logloss:  0.3493 - val_auc:  0.7784 - val_logloss:  0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:18, 24.89s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 4495\n",
      "4495s - loss:  0.4131 - auc:  0.8131 - logloss:  0.3474 - val_auc:  0.7795 - val_logloss:  0.3662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:28, 24.96s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 4518\n",
      "4518s - loss:  0.4110 - auc:  0.8153 - logloss:  0.3456 - val_auc:  0.7833 - val_logloss:  0.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:40, 25.04s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 4513\n",
      "4513s - loss:  0.4097 - auc:  0.8175 - logloss:  0.3442 - val_auc:  0.7885 - val_logloss:  0.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:54, 25.13s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 4527\n",
      "4527s - loss:  0.4080 - auc:  0.8201 - logloss:  0.3424 - val_auc:  0.7863 - val_logloss:  0.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:24, 24.93s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 4498\n",
      "4498s - loss:  0.4062 - auc:  0.8220 - logloss:  0.3407 - val_auc:  0.7861 - val_logloss:  0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:04:46, 25.08s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 4519\n",
      "4519s - loss:  0.4047 - auc:  0.8240 - logloss:  0.3390 - val_auc:  0.7812 - val_logloss:  0.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [1:06:31, 25.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 4620\n",
      "4620s - loss:  0.4029 - auc:  0.8270 - logloss:  0.3374 - val_auc:  0.7822 - val_logloss:  0.3667\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': (WDL(\n",
       "    (embedding_dict): ModuleDict()\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 1)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (user_gender): Embedding(4, 1)\n",
       "        (user_age_level): Embedding(10, 1)\n",
       "        (user_purchase_level): Embedding(12, 1)\n",
       "      )\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "  ),\n",
       "  {'eval_auc': 0.7376626895666603, 'eval_logloss': 0.3896957549594237},\n",
       "  array([[0.07969326],\n",
       "         [0.34986228],\n",
       "         [0.11643843],\n",
       "         ...,\n",
       "         [0.19720304],\n",
       "         [0.20960759],\n",
       "         [0.106845  ]]),\n",
       "  1640     0\n",
       "  16371    0\n",
       "  30974    0\n",
       "  40893    0\n",
       "  21170    0\n",
       "          ..\n",
       "  40561    0\n",
       "  36709    0\n",
       "  45091    0\n",
       "  43526    1\n",
       "  30409    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'xgBoost': (<xgboost.core.Booster at 0x2ae67f293e10>,\n",
       "  {'eval_auc': 0.7759336510651825, 'eval_logloss': 0.36399786090749175},\n",
       "  array([0.20262565, 0.23141274, 0.266697  , ..., 0.25140867, 0.3471386 ,\n",
       "         0.0204258 ], dtype=float32),\n",
       "  29554    0\n",
       "  7460     0\n",
       "  28354    0\n",
       "  44182    0\n",
       "  3480     0\n",
       "          ..\n",
       "  50378    0\n",
       "  25616    0\n",
       "  43253    1\n",
       "  20361    1\n",
       "  21538    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'DNN': (WDL(\n",
       "    (embedding_dict): ModuleDict(\n",
       "      (promotion_id): Embedding(462, 16)\n",
       "      (session_id): Embedding(58052, 16)\n",
       "      (user_gender): Embedding(4, 16)\n",
       "      (user_age_level): Embedding(10, 16)\n",
       "      (user_purchase_level): Embedding(12, 16)\n",
       "    )\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict()\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "    (dnn): DNN(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=88, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  ),\n",
       "  {'eval_auc': 0.7617967773393335, 'eval_logloss': 0.3774919966116668},\n",
       "  array([[0.08486187],\n",
       "         [0.36818951],\n",
       "         [0.09922744],\n",
       "         ...,\n",
       "         [0.16687077],\n",
       "         [0.17473376],\n",
       "         [0.08285475]]),\n",
       "  1640     0\n",
       "  16371    0\n",
       "  30974    0\n",
       "  40893    0\n",
       "  21170    0\n",
       "          ..\n",
       "  40561    0\n",
       "  36709    0\n",
       "  45091    0\n",
       "  43526    1\n",
       "  30409    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'WDL': (WDL(\n",
       "    (embedding_dict): ModuleDict(\n",
       "      (promotion_id): Embedding(462, 16)\n",
       "      (session_id): Embedding(58052, 16)\n",
       "      (user_gender): Embedding(4, 16)\n",
       "      (user_age_level): Embedding(10, 16)\n",
       "      (user_purchase_level): Embedding(12, 16)\n",
       "    )\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 1)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (user_gender): Embedding(4, 1)\n",
       "        (user_age_level): Embedding(10, 1)\n",
       "        (user_purchase_level): Embedding(12, 1)\n",
       "      )\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "    (dnn): DNN(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=88, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  ),\n",
       "  {'eval_auc': 0.7715598802105996, 'eval_logloss': 0.37170696515557294},\n",
       "  array([[0.06616073],\n",
       "         [0.33113384],\n",
       "         [0.14103581],\n",
       "         ...,\n",
       "         [0.14911394],\n",
       "         [0.16595915],\n",
       "         [0.07432426]]),\n",
       "  1640     0\n",
       "  16371    0\n",
       "  30974    0\n",
       "  40893    0\n",
       "  21170    0\n",
       "          ..\n",
       "  40561    0\n",
       "  36709    0\n",
       "  45091    0\n",
       "  43526    1\n",
       "  30409    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'DIN': (DataParallel(\n",
       "    (module): DIN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (session_id): Embedding(58052, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7772530545594571, 'eval_logloss': 0.3688490173961206},\n",
       "  array([[0.04729629],\n",
       "         [0.37110004],\n",
       "         [0.2351685 ],\n",
       "         ...,\n",
       "         [0.06019634],\n",
       "         [0.20133978],\n",
       "         [0.04087048]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 0, 1, 0])),\n",
       " 'DMBGN_AvgPooling': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (session_id): Embedding(462, 32)\n",
       "        (promotion_id): Embedding(462, 32)\n",
       "        (sid): Embedding(58052, 16)\n",
       "        (hist_promotion_id): Embedding(462, 32)\n",
       "        (hist_session_id): Embedding(58052, 32)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7789309931033939, 'eval_logloss': 0.3683940282657804},\n",
       "  array([[0.03235466],\n",
       "         [0.45377716],\n",
       "         [0.3876149 ],\n",
       "         ...,\n",
       "         [0.13748574],\n",
       "         [0.18753178],\n",
       "         [0.09012988]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 0, 1, 0])),\n",
       " 'DMBGN_Pretrained': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (sid): Embedding(462, 16)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "        (hist_sid): Embedding(58052, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7804235856293115, 'eval_logloss': 0.36804150822689047},\n",
       "  array([[0.04374835],\n",
       "         [0.24823132],\n",
       "         [0.3314173 ],\n",
       "         ...,\n",
       "         [0.07344288],\n",
       "         [0.42903283],\n",
       "         [0.00324636]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 1, 1, 0])),\n",
       " 'DMBGN': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (sid): Embedding(462, 16)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "        (hist_sid): Embedding(58052, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=130, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "      (gnet): VoucherGraphNet(\n",
       "        (emb_dic): ModuleDict(\n",
       "          (atc_emb): Embedding(344082, 16)\n",
       "          (ord_emb): Embedding(344082, 16)\n",
       "          (item_category_id): Embedding(6000, 1)\n",
       "          (item_price_level): Embedding(300, 1)\n",
       "          (promotion_id): Embedding(600, 16)\n",
       "          (voucher_min_spend): Embedding(500, 1)\n",
       "          (voucher_discount_amount): Embedding(500, 1)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): GraphConv(18, 16)\n",
       "          (1): GraphConv(16, 16)\n",
       "        )\n",
       "        (pools): ModuleList(\n",
       "          (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "          (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "        )\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gnet_before): VoucherGraphNet(\n",
       "        (emb_dic): ModuleDict(\n",
       "          (atc_emb): Embedding(344082, 16)\n",
       "          (ord_emb): Embedding(344082, 16)\n",
       "          (item_category_id): Embedding(6000, 1)\n",
       "          (item_price_level): Embedding(300, 1)\n",
       "          (promotion_id): Embedding(600, 16)\n",
       "          (voucher_min_spend): Embedding(500, 1)\n",
       "          (voucher_discount_amount): Embedding(500, 1)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): GraphConv(18, 16)\n",
       "          (1): GraphConv(16, 16)\n",
       "        )\n",
       "        (pools): ModuleList(\n",
       "          (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "          (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "        )\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7885038103233506, 'eval_logloss': 0.36155839320561034},\n",
       "  array([[0.01185647],\n",
       "         [0.20440318],\n",
       "         [0.12882197],\n",
       "         ...,\n",
       "         [0.06300204],\n",
       "         [0.32901135],\n",
       "         [0.00128472]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 1, 1, 0]))}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "i = 0\n",
    "lw = 1\n",
    "\n",
    "colors = [\"cornflowerblue\", \"darkorange\", \"red\", \"blue\", \"green\", \"violet\", \"black\", \"purple\", \"olive\", \"cyan\"]\n",
    "\n",
    "\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_label1.astype(int),  pred1)\n",
    "    roc_auc = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=lw, label = model_name + ' ROC curve (area = ' + str(round(roc_auc, 4)) + ')')\n",
    "\n",
    "    i += 1\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "plt.title('User-Voucher Redemption Dataset ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+---------------+---------------+---------+\n",
      "|      Model       |  AUC   | RelaImpr(DNN) | RelaImpr(DIN) | Logloss |\n",
      "+------------------+--------+---------------+---------------+---------+\n",
      "|        LR        | 0.7377 |     -9.22%    |    -14.28%    |  0.3897 |\n",
      "|     xgBoost      | 0.7759 |     5.40%     |     -0.48%    |  0.3640 |\n",
      "|       DNN        | 0.7618 |     0.00%     |     -5.57%    |  0.3775 |\n",
      "|       WDL        | 0.7716 |     3.73%     |     -2.05%    |  0.3717 |\n",
      "|       DIN        | 0.7773 |     5.90%     |     0.00%     |  0.3688 |\n",
      "| DMBGN_AvgPooling | 0.7789 |     6.54%     |     0.61%     |  0.3684 |\n",
      "| DMBGN_Pretrained | 0.7804 |     7.11%     |     1.14%     |  0.3680 |\n",
      "|      DMBGN       | 0.7885 |     10.20%    |     4.06%     |  0.3616 |\n",
      "+------------------+--------+---------------+---------------+---------+\n"
     ]
    }
   ],
   "source": [
    "def relaImpr(a, b):\n",
    "    x = ((a-0.5)/(b-0.5) - 1.0)*100.0\n",
    "    return str(\"%.2f\" % x) + '%'\n",
    "\n",
    "dnn_auc = results['DNN'][1]['eval_auc']\n",
    "din_auc = results['DIN'][1]['eval_auc']\n",
    "\n",
    "table = PrettyTable(['Model','AUC','RelaImpr(DNN)','RelaImpr(DIN)', 'Logloss'], digits = 4, rounds=True)\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    table.add_row([model_name, \"%.4f\" % res['eval_auc'], relaImpr(res['eval_auc'], dnn_auc), relaImpr(res['eval_auc'], din_auc), \"%.4f\" % res['eval_logloss']])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that xgBoost has a higher AUC compared to DNN and WDL, mainly due to the small sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al.2013.  Ad click prediction: a view from the trenches. InProceedings of the 19thACM SIGKDD international conference on Knowledge discovery and data mining.1222–1230.\n",
    "- [2] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree.Advances in neural information processing systems30 (2017), 3146–3154.\n",
    "- [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, RohanAnil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.2016. Wide & Deep Learning for Recommender Systems.CoRRabs/1606.07792(2016). arXiv:1606.07792  http://arxiv.org/abs/1606.07792 .\n",
    "- [4] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, YanghuiYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-throughrate prediction. InProceedings of the 24th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining. 1059–1068."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
